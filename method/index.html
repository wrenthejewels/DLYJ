<!DOCTYPE html>
<html lang='en'>

<head>
    <meta charset='UTF-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0'>
    <link rel='preconnect' href='https://fonts.googleapis.com'>
    <link rel='preconnect' href='https://fonts.gstatic.com' crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=IBM+Plex+Mono:wght@400;500&family=Bebas+Neue&display=swap" rel="stylesheet">
    <title>Methodology - Don't Lose Your Job</title>
    <style>
        :root {
            /* Warm neutral palette */
            --bg-page: #FAF8F5;
            --bg-card: #FFFFFF;
            --bg-subtle: #F5F2EE;
            --bg-hover: #F0EDE8;

            /* Text hierarchy */
            --text-primary: #1A1917;
            --text-secondary: #5C5850;
            --text-tertiary: #8A8578;

            /* Accent - blue to match page theme */
            --accent: #2a5298;
            --accent-hover: #1e3c72;
            --accent-subtle: rgba(42, 82, 152, 0.08);

            /* Borders */
            --border-light: #E8E4DE;
            --border-medium: #D9D4CC;

            /* Spacing scale */
            --space-1: 4px;
            --space-2: 8px;
            --space-3: 12px;
            --space-4: 16px;
            --space-5: 24px;
            --space-6: 32px;
            --space-7: 48px;
            --space-8: 64px;

            /* Typography scale */
            --text-xs: 0.75rem;
            --text-sm: 0.875rem;
            --text-base: 1rem;
            --text-lg: 1.125rem;
            --text-xl: 1.25rem;
            --text-2xl: 1.5rem;
            --text-3xl: 2rem;

            /* Radius */
            --radius-sm: 6px;
            --radius-md: 10px;
            --radius-lg: 16px;
            --radius-full: 9999px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Prevent horizontal overflow on mobile */
        html, body {
            overflow-x: hidden;
            max-width: 100vw;
        }

        html {
            scroll-behavior: smooth;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: var(--bg-page);
            color: var(--text-primary);
            line-height: 1.6;
            min-height: 100vh;
        }

        a {
            color: var(--accent);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.2s ease;
        }

        a:hover {
            color: var(--accent-hover);
            text-decoration: underline;
        }

        .container {
            width: 92.5%;
            max-width: none;
            margin: 0 auto;
            padding: 0 0 120px;
            background: transparent;
        }

        @media (max-width: 768px) {
            .container {
                width: 96%;
                padding: 0 0 80px;
            }
        }

        @media (max-width: 480px) {
            .container {
                width: 98%;
                padding: 0 0 60px;
            }
        }

        .content-wrapper {
            width: 100%;
            margin: 0 auto;
        }

        .site-header, .header {
            position: static;
            background: var(--bg-page);
            border-bottom: 1px solid var(--border-light);
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.04);
            z-index: 100;
        }

        .centered-header {
            border-bottom: 1px solid var(--border-light);
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.04);
            padding: 0;
        }

        .centered-header .header-inner {
            flex-direction: row;
            align-items: center;
            justify-content: space-between;
            gap: 16px;
            text-align: left;
        }

        .header-inner {
            max-width: 1200px;
            margin: 0 auto;
            padding: var(--space-4) var(--space-5);
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: var(--space-5);
        }

        .brand, .header-brand {
            display: flex;
            align-items: center;
            gap: 6px;
            flex-direction: row;
        }

        .centered-brand,
        .centered-header .header-brand {
            align-items: center;
            flex: 1;
        }

        .brand-name, .publication-title {
            font-size: var(--text-sm);
            font-weight: 700;
            color: var(--text-primary);
            letter-spacing: -0.01em;
            line-height: 1;
            padding: var(--space-3) 0;
            display: inline-flex;
            flex-direction: row;
            gap: 0.35ch;
            white-space: nowrap;
        }

        .publication-title {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 1.75rem;
            letter-spacing: 0.05em;
            font-weight: 400;
            text-transform: uppercase;
            color: #1A1917;
        }

        .publication-title span {
            display: inline;
        }

        .author-name-header {
            font-family: 'Inter', sans-serif;
            font-size: 0.875rem;
            letter-spacing: 0.01em;
            text-transform: none;
            font-style: italic;
            color: #8A8578;
            font-weight: 400;
        }

        .nav {
            display: flex;
            gap: var(--space-2);
        }

        .centered-header .nav {
            margin-left: auto;
        }
        .nav-link {
            padding: 14px 30px;
            font-size: 1.05rem;
            font-weight: 500;
            color: var(--text-secondary);
            border-radius: var(--radius-full);
            transition: all 0.15s ease;
            text-decoration: none;
        }

        .nav-link:hover {
            color: var(--text-primary);
            background: var(--bg-subtle);
        }

        .nav-link.active {
            color: var(--text-primary);
            background: var(--bg-card);
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
            text-decoration: underline;
        }

        /* Sticky progress rail (desktop only) -- LessWrong-inspired */
        .progress-nav {
            --progress-fill: 0%;
            position: fixed;
            top: 150px;
            left: 24px;
            width: 240px;
            max-height: 86vh;
            padding: 10px 14px 12px 16px;
            background: rgba(245, 242, 238, 0.96);
            border: 1px solid #e5e7eb;
            border-radius: 14px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.05);
            backdrop-filter: blur(8px);
            overflow-y: auto;
            overflow-x: hidden;
            font-size: 0.9rem;
            display: none;
            z-index: 120;
            scrollbar-width: none;
            -ms-overflow-style: none;
        }

        @media (min-width: 1100px) {
            .progress-nav {
                display: block;
            }
        }

        .progress-nav h4 {
            margin: 0 0 12px;
            font-size: 0.82rem;
            color: #4b5563;
            letter-spacing: 0.06em;
            text-transform: uppercase;
        }

        .progress-nav ul {
            position: relative;
            list-style: none;
            padding: 6px 0 6px 18px;
            margin: 0;
        }

        .progress-nav ul::before {
            content: "";
            position: absolute;
            left: 6px;
            top: 8px;
            bottom: 8px;
            width: 2px;
            background: rgba(26, 25, 23, 0.2);
            border-radius: 999px;
        }

        .progress-nav ul::after {
            content: "";
            position: absolute;
            left: 6px;
            top: 8px;
            width: 2px;
            height: var(--progress-fill, 0%);
            background: #1A1917;
            border-radius: 999px;
            transition: height 0.18s ease;
        }

        .progress-nav li {
            position: relative;
            margin: 0 0 8px;
            padding-left: 2px;
        }

        .progress-nav li.depth-2 {
            margin-top: 12px;
        }

        .progress-nav li:last-child {
            margin-bottom: 0;
        }

        .progress-nav a {
            position: relative;
            color: #4b5563;
            text-decoration: none;
            display: block;
            padding: 8px 10px 8px 14px;
            border-radius: 10px;
            transition: color 0.15s ease, background 0.15s ease, border-color 0.15s ease;
            line-height: 1.3;
        }

        .progress-nav a.depth-2 {
            font-size: 0.95rem;
            font-weight: 700;
            color: #111827;
            background: rgba(26, 25, 23, 0.03);
            border: 1px solid transparent;
            padding-left: 16px;
        }

        .progress-nav a:hover {
            color: #1f2937;
            background: rgba(42, 82, 152, 0.06);
        }

        .progress-nav a.active {
            color: #1f2937;
            background: rgba(42, 82, 152, 0.12);
            font-weight: 700;
            border-color: rgba(42, 82, 152, 0.18);
        }

        .progress-nav::-webkit-scrollbar {
            display: none;
        }

        .progress-nav li.depth-3 {
            margin: 6px 0 6px 14px;
            padding-left: 12px;
            border-left: 2px solid #e5e7eb;
        }

        .progress-nav a.depth-3 {
            padding-left: 12px;
            font-size: 0.86rem;
            color: #4b5563;
            font-weight: 500;
        }

        .progress-nav li.depth-3.active {
            border-left-color: rgba(42, 82, 152, 0.35);
        }

        .guide-article {
            width: 100%;
        }

        .hero, .hero-section {
            text-align: center;
            padding: var(--space-8) 0 var(--space-7);
            max-width: 720px;
            margin: 0 auto;
            background: transparent;
            border-bottom: none;
        }

        .hero h1, .hero-section h1 {
            font-family: 'Inter', sans-serif;
            font-size: clamp(var(--text-3xl), 5vw, 3.5rem);
            font-weight: 600;
            line-height: 1.25;
            letter-spacing: -0.02em;
            color: var(--text-primary);
            margin-bottom: var(--space-4);
        }

        .hero p, .hero-section p {
            font-size: 1rem;
            color: var(--text-secondary);
            max-width: 540px;
            margin: 6px auto 0;
            line-height: 1.55;
        }

        .article-hero {
            text-align: center;
            padding: 62px 0 32px;
            max-width: 720px;
            margin: 0 auto 48px;
            background: transparent;
            border-bottom: 1px solid #e6e0d4;
            box-shadow: 0 1px 2px rgba(0, 0, 0, 0.03);
        }

        .article-hero h1 {
            font-family: 'Inter', sans-serif;
            font-size: clamp(1.9rem, 3vw, 2.6rem);
            letter-spacing: -0.015em;
            font-weight: 600;
            margin-top: 18px;
        }

        .lede, .article-hero p {
            font-size: 1rem;
            color: var(--text-secondary);
            max-width: 540px;
            margin: 6px auto 0;
            line-height: 1.55;
        }

        .meta-line {
            display: flex;
            gap: 16px;
            align-items: center;
            justify-content: center;
            margin-top: 24px;
            font-size: 0.85rem;
            letter-spacing: 0.12em;
            text-transform: uppercase;
            color: #8c857d;
        }

        .article-body {
            width: min(1300px, 98%);
            margin: 0 auto;
            display: flex;
            flex-direction: column;
            gap: 48px;
            padding-bottom: 120px;
        }

        .metr-intro {
            display: flex;
            flex-direction: column;
            gap: 32px;
        }

        .metr-brand-card {
            background: #fdf8f0;
            border: 1px solid #e6e0d4;
            border-radius: 18px;
            padding: 28px;
            margin-bottom: 48px;
            box-shadow: 0 24px 60px rgba(15, 23, 42, 0.06);
            width: 100%;
        }

        .metr-brand-link {
            display: flex;
            align-items: center;
            gap: 16px;
            margin-bottom: 24px;
        }

        .metr-brand-link img {
            width: 56px;
            height: auto;
        }

        .metr-brand-text {
            display: flex;
            flex-direction: column;
            gap: 4px;
        }

        .metr-brand-title {
            font-family: 'Inter', sans-serif;
            font-size: 1.15rem;
            letter-spacing: 0.1em;
            color: #1f1c18;
            text-transform: uppercase;
        }

        .metr-brand-subtitle {
            font-size: 0.95rem;
            color: #5c564f;
        }

        .metr-figure {
            background: #ffffff;
            border: 1px solid #e6e0d4;
            border-radius: 18px;
            padding: 20px;
            box-shadow: 0 24px 60px rgba(15, 23, 42, 0.05);
            width: 100%;
        }

        .metr-figure img {
            width: 100%;
            height: auto;
            border-radius: 12px;
        }

        .metr-figure figcaption {
            margin-top: 12px;
            font-size: 0.9rem;
            color: #6b635a;
        }

        .chart-note {
            margin-top: 18px;
            font-size: 0.92rem;
            color: #5c564f;
        }

        .article-body section {
            background: #ffffff;
            border: 1px solid #e6e0d4;
            border-radius: 24px;
            padding: 40px 44px;
            box-shadow: 0 32px 80px rgba(15, 23, 42, 0.05);
        }

        .article-body h2 {
            font-family: 'Inter', sans-serif;
            font-size: 1.8rem;
            margin-bottom: 24px;
            color: var(--text-primary);
        }

        .article-body h3 {
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            margin: 32px 0 16px;
            color: var(--text-primary);
        }

        .article-body h3.h3-accent {
            color: #2a5298;
            margin: 26px 0 12px 0;
            font-size: 1.05em;
        }

        .article-body p {
            margin-bottom: 1.4em;
            color: var(--text-primary);
        }

        code {
            font-family: 'IBM Plex Mono', 'Menlo', monospace;
            font-size: 0.95rem;
            background: #f5efe4;
            color: var(--text-primary);
            padding: 0 4px;
            border-radius: 4px;
        }

        blockquote {
            border-left: 4px solid #d2c7b8;
            padding-left: 20px;
            margin: 24px 0;
            color: #5c564f;
            font-style: italic;
        }

        .equation-callout {
            margin: 28px 0;
            padding: 24px 28px;
            border-left: 4px solid #d2c7b8;
            background: var(--bg-subtle);
            border-radius: 18px;
        }

        .callout-label {
            display: block;
            font-size: 0.8rem;
            letter-spacing: 0.12em;
            color: var(--text-secondary);
            text-transform: uppercase;
            margin-bottom: 10px;
            font-weight: 600;
        }

        .equation-display {
            font-size: 1.1rem;
            color: var(--text-primary);
            overflow-x: auto;
            padding: 8px 0;
        }

        .detail-list {
            list-style: none;
            padding: 0;
            margin: 24px 0;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        .detail-list li {
            background: var(--bg-subtle);
            border: 1px solid #eadfce;
            border-radius: 16px;
            padding: 16px 20px;
            color: var(--text-primary);
        }

        .detail-list li strong {
            display: inline;
            font-family: 'Inter', sans-serif;
            font-size: 0.95rem;
            margin: 0;
            margin-right: 6px;
        }

        .insight-callout {
            border-left: 4px solid #d2c7b8;
            background: #fdf7ed;
            border-radius: 18px;
            padding: 20px 24px;
            margin: 28px 0;
            color: var(--text-primary);
            font-size: 0.95rem;
        }

        .insight-callout strong {
            font-family: 'Inter', sans-serif;
        }

        .insight-callout h4 {
            margin: 0 0 12px 0;
            font-size: 1.05rem;
            font-weight: 600;
            color: var(--text-primary);
        }

        .insight-callout p {
            margin-bottom: 0.8em;
        }

        .insight-callout p:last-child {
            margin-bottom: 0;
        }

        .insight-callout ul {
            margin: 0 0 0 20px;
            padding: 0;
        }

        .insight-callout ul li {
            margin-bottom: 8px;
        }

        .insight-callout ul li:last-child {
            margin-bottom: 0;
        }

        /* Parameter table component for data tables */
        .parameter-table {
            margin: 24px 0;
            padding: 20px;
            background: var(--bg-subtle);
            border: 1px solid #eadfce;
            border-radius: 18px;
            overflow-x: auto;
        }

        .parameter-table table {
            margin: 0 auto;
            border-collapse: collapse;
            font-family: 'IBM Plex Mono', monospace;
            width: 100%;
            font-size: 0.9rem;
        }

        .parameter-table th,
        .parameter-table td {
            padding: 8px 12px;
            text-align: left;
        }

        .parameter-table th {
            background: var(--bg-page);
            font-weight: 600;
            color: var(--text-primary);
            border-bottom: 1px solid #d9d4cc;
        }

        .parameter-table td {
            border-bottom: 1px solid #eadfce;
        }

        .parameter-table tr:last-child td {
            border-bottom: none;
        }

        .parameter-table .table-label {
            margin: 0 0 12px 0;
            font-family: 'Inter', sans-serif;
            font-size: 0.95rem;
            font-weight: 600;
            color: var(--text-secondary);
        }

        /* Compact bubble table for defaults */
        .bubble-table {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(340px, 1fr));
            gap: 16px;
            margin: 16px 0 24px;
        }

        @media (max-width: 480px) {
            .bubble-table {
                grid-template-columns: 1fr;
            }
        }
        .bubble-item {
            background: var(--bg-subtle);
            border: 1px solid #eadfce;
            border-radius: 16px;
            padding: 14px 16px;
            display: flex;
            align-items: flex-start;
            justify-content: space-between;
            gap: 12px;
            overflow: visible;
        }
        .bubble-key {
            font-family: 'Inter', sans-serif;
            font-weight: 600;
            color: var(--text-primary);
            flex: 1 1 auto;
            font-size: 0.85rem;
            white-space: normal;
            overflow: visible;
            min-width: 0;
            line-height: 1.3;
        }
        .bubble-val {
            color: var(--text-secondary);
            text-align: right;
            flex-shrink: 0;
            font-size: 0.84rem;
            white-space: normal;
            max-width: 180px;
            line-height: 1.3;
        }

        ol.action-list {
            counter-reset: step;
            list-style: none;
            padding: 0;
            margin: 24px 0;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        ol.action-list li {
            counter-increment: step;
            position: relative;
            padding: 18px 20px 18px 54px;
            background: var(--bg-subtle);
            border: 1px solid #eadfce;
            border-radius: 18px;
            color: var(--text-primary);
        }

        ol.action-list li::before {
            content: counter(step);
            position: absolute;
            left: 18px;
            top: 18px;
            width: 28px;
            height: 28px;
            border-radius: 50%;
            background: #1f1c18;
            color: #ffffff;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.85rem;
            font-weight: 600;
        }

        @media (max-width: 900px) {
            .header-inner {
                width: 94%;
            }

            .article-body section {
                padding: 32px;
            }
        }

        @media (max-width: 640px) {
            .header-inner {
                flex-direction: column;
                align-items: center;
                gap: 16px;
                padding: 12px 16px;
                text-align: center;
                width: 100%;
                max-width: 100%;
            }

            .centered-header .header-brand {
                align-items: center;
                justify-content: center;
                width: 100%;
                flex: none;
            }

            .centered-header .nav {
                margin-left: 0;
                justify-content: center;
                width: 100%;
            }

            .nav {
                flex-wrap: wrap;
                justify-content: center;
                gap: 8px;
            }

            .nav-link {
                padding: 8px 12px;
                font-size: 0.85rem;
            }

            .centered-header .header-inner {
                flex-direction: column;
                align-items: center;
                gap: 12px;
                padding: 12px 16px;
            }

            .publication-title {
                font-size: 1.4rem;
            }

            .hero-section {
                padding: 56px 16px 36px;
            }

            .article-hero {
                padding: 56px 16px 32px;
            }

            .article-hero h1 {
                font-size: clamp(1.8rem, 6vw, 2.4rem);
                margin-top: 12px;
                letter-spacing: -0.01em;
            }

            .hero-section h1 {
                font-size: clamp(1.6rem, 6vw, 2.2rem);
                letter-spacing: -0.01em;
            }

            .lede {
                font-size: 0.95rem;
                max-width: 100%;
                line-height: 1.6;
            }

            .article-body section {
                padding: 20px 16px;
                border-radius: 16px;
            }

            .article-body h2 {
                font-size: 1.4rem;
                margin-bottom: 16px;
            }

            .article-body h3 {
                font-size: 1.05rem;
            }

            .article-body p {
                font-size: 0.95rem;
            }

            .detail-list li {
                padding: 12px 14px;
                font-size: 0.9rem;
            }

            .equation-callout {
                padding: 16px 14px;
                border-radius: 12px;
            }

            .equation-display {
                font-size: 0.95rem;
                overflow-x: auto;
            }

            #model-flow-diagram {
                min-width: 550px;
            }

            .bubble-table {
                grid-template-columns: 1fr;
            }

            .bubble-item {
                padding: 12px 14px;
                gap: 8px;
                flex-wrap: wrap;
                align-items: flex-start;
            }

            .bubble-key {
                font-size: 0.80rem;
                flex: 1 1 100%;
                text-align: left;
                overflow: visible;
                white-space: normal;
            }

            .bubble-val {
                font-size: 0.79rem;
                flex: 1 1 100%;
                text-align: left;
                padding-left: 8px;
                color: #5c564f;
            }

            ol.action-list li {
                padding: 16px 18px 16px 48px;
            }

            ol.action-list li::before {
                left: 14px;
                top: 16px;
            }
        }

        @media (max-width: 380px) {
            .container {
                width: 100%;
            }

            .article-hero {
                padding: 56px 16px 32px;
            }

            .article-hero h1 {
                font-size: 1.5rem;
            }

            .article-body section {
                padding: 16px 12px;
                border-radius: 12px;
            }

            .nav-link {
                padding: 8px 12px;
                font-size: 0.85rem;
            }

            .metr-brand-card {
                padding: 16px;
            }

            .metr-figure {
                padding: 12px;
            }
        }
    </style>
</head>

<body>
    <nav class="progress-nav" aria-label="On this page">
        <ul id="progress-list" class="progress-rail"></ul>
    </nav>
    <header class="site-header centered-header">
        <div class="header-inner">
            <div class="header-brand centered-brand">
                <a href="/" style="text-decoration: none; color: inherit; cursor: pointer;">
                    <span class="publication-title">Don't Lose Your Job
                </a>
            </div>
            <nav class="nav">
                <a href="/" class="nav-link">Model</a>
                <a href="/guide" class="nav-link">Guide</a>
                <a href="/method" class="nav-link active">Methodology</a>
            </nav>
        </div>
    </header>

    <main class='container'>
        <div class='content-wrapper'>
            <article class='guide-article'>
                <header class='article-hero'>
                    <h1>Methodology</h1>
                    <p class='lede'>Technical breakdown of the hazard model, mathematical framework, and advanced model tuning.</p>
                </header>

                <div class='article-body'>

                    <section class="metr-intro">

                        <h2>Modeling capability growth and job loss</h2>

                        <div class="metr-brand-card">

                            <a class="metr-brand-link" href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" target="_blank" rel="noopener noreferrer">

                                <img src="../images/metr-logo.svg" alt="METR logo">

                                <div class="metr-brand-text">

                                    <span class="metr-brand-title">METR

                                    <span class="metr-brand-subtitle">Measuring AI ability to complete long tasks

                                </div>

                            </a>

                            <p>METR measures how long frontier AI agents can work autonomously before they start failing. Since 2019, this task horizon (the longest task duration at which AI succeeds 50% of the time) has doubled roughly every seven months.</p>

                            <p>On each page load, the calculator pulls the full METR benchmark dataset and identifies the latest state-of-the-art (SOTA) model (currently GPT-5.1-Codex-Max, November 2025) as the capability baseline. It <strong>calculates the doubling time automatically</strong> via linear regression across all historical SOTA models, so the trend reflects actual measured progress rather than a hardcoded assumption. Your current date serves as the projection starting point.</p>

                            <p>For example, GPT-5.1-Codex-Max shows a 50th percentile task horizon of ~162 minutes and an 80% success horizon of ~31 minutes. We fit a logistic success curve through these measurements, and at the default 95% reliability requirement, the effective horizon contracts significantly to about 33&times; shorter than the median, or ~235&times; shorter at 99% reliability (see <em>Reliability penalty</em> below for why).</p>

                            <ul class="detail-list">

                                <li><strong>Doubling trend:</strong> Computed dynamically from METR data via linear regression (typically ~6-7 months). The calculator fits log<sub>2</sub>(p50) against time across all SOTA models to derive the current doubling rate.</li>

                                <li><strong>Reliability gate:</strong> We require 95% success before automation kicks in—high enough that failures are rare in production use. You can adjust this threshold in the calculator.</li>

                                <li><strong>Task mapping:</strong> Your job gets decomposed into five task duration buckets: [5, 30, 120, 360, 720] minutes (roughly &lt;10 min, 10-45 min, 45 min-3 hr, 3-8 hr, and &gt;12 hr tasks). These thresholds are calibrated for corporate production work. Once AI can reliably complete enough of these categories, the hazard channel opens.</li>


                            </ul>

                        </div>

                        <figure class="metr-figure">

                            <img src="../images/metr-length-of-tasks-linear.png" alt="METR linear task horizon trend">

                            <figcaption>
                                Source: <a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" target="_blank" rel="noopener noreferrer">METR study</a>
                            </figcaption>

                        </figure>

                    </section>
                    <section>
                        <h2>What the calculator actually simulates</h2>
                        <p>The calculator models job displacement as a survival problem: it estimates the probability that you lose your job by time $t$, given that you haven't lost it yet. The hazard rate $\lambda(t)$ represents instantaneous risk at each moment—higher hazard means faster accumulation of displacement probability. While a complete model would include macroeconomic forces, firm performance, layoffs, and other non-AI risks, this calculator focuses solely on AI-related hazards at the role, personal, and firm levels. The output represents one component of your total displacement risk, not the whole picture.</p>
                        <p>How capability flows: METR data gives the starting task length, reliability penalty, and doubling time; your answers set domain friction (barriers that slow AI adoption in your specific role) and the industry slider; those shrink the effective horizon that feeds the task gates. <strong>All</strong> of the coefficients in this model can be tweaked in the Model Tuning section, including the task doubling rate.</p>
                        <div class='equation-callout'>
                            <span class='callout-label'>Survival relationship</span>
                            <div class='equation-display'>$$P_{\text{loss}}(t) = 1 - \exp\left(-\int_0^t \lambda_{\text{total}}(s)\, ds\right)$$</div>
                            <span class='callout-label'>Stacked hazard model</span>
                            <div class='equation-display'>$$\lambda_{\text{total}}(s) = \lambda_{\text{AI}}(s) + \lambda_{\text{macro}}(s) + \lambda_{\text{firm}}(s) + \lambda_{\text{role}}(s) + \lambda_{\text{personal}}(s)$$</div>
                        </div>
                        <p>The AI hazard rate ($\lambda_{\text{AI}}(s)$) determines the blue technical feasibility curve. Your firm and personal questionnaire responses then delay this hazard (shifting the curve rightward) while adding a separate compression hazard channel, together producing the green implementation curve. The same questionnaire data also determines your re-employment probability.</p>
                        <ul class='detail-list'>
                            <li><strong>AI hazard (blue curve):</strong> METR task-length data maps capability progress into technical feasibility.</li>
                            <li><strong>Compression hazard (green curve only):</strong> Workforce reductions via task reallocation to AI-amplified seniors, activated at lower capability thresholds for vulnerable hierarchy positions.</li>
                            <li><strong>Implementation delay (green curve):</strong> Firm and personal answers shift the AI automation hazard forward in time.</li>
                            <li><strong>Re-employment likelihood:</strong> Adaptability and transferable skill questions translate into the percentage you see on the dashboard.</li>
                        </ul>

                        <h3>Why a Hazard Model</h3>

                        <p>When modeling job displacement, we face a fundamental question: what kind of mathematical framework captures how this process actually works? We chose a hazard model-<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2394262/" target="_blank" rel="noopener noreferrer">hazard framework</a>-for specific reasons that matter for interpreting the results.</p>

                        <p><strong>The nature of displacement risk:</strong> Job displacement doesn't happen on a fixed date. Instead, risk accumulates continuously over time. Each day you remain employed, conditions might align to eliminate your role. Rather than asking "when will I be displaced?" we need to estimate displacement probability over different time horizons.</p>

                        <p>Hazard models capture this structure. They calculate the instantaneous rate of an event occurring, given it hasn't occurred yet:</p>

                        <ul class="detail-list">
                            <li><strong>Risk changes over time:</strong> Your displacement probability isn't constant—it increases as AI capabilities grow, as your organization matures its adoption, and as the economic case strengthens. Hazard models naturally incorporate time-varying risk.</li>
                            <li><strong>Multiple factors combine:</strong> Displacement results from the intersection of technical capability, organizational readiness, economic conditions, and individual factors. Hazard models allow these to combine multiplicatively in ways that match how real-world risk accumulates.</li>
                            <li><strong>Survival curves are meaningful:</strong> The output isn't a prediction of "you'll be displaced in 3.7 years." It's a probability distribution—a 40% chance within 3 years, 70% within 5 years, etc. This reflects the genuine uncertainty about timing while providing actionable probability estimates.</li>
                        </ul>

                        <p><strong>What hazard models get right:</strong> Hazard models align well with how displacement actually works:</p>

                        <ul class="detail-list">
                            <li><strong>Absorbing state:</strong> Once you're displaced from a specific role, you can't be "un-displaced" from it. You might find new employment, but that's a different role. Hazard models naturally handle events that can only happen once.</li>
                            <li><strong>Censoring:</strong> We don't observe everyone's displacement—some people retire, quit, or are observed for limited periods. Hazard models handle this "censoring" correctly, using partial information without biasing estimates.</li>
                            <li><strong>Competing risks:</strong> You might leave your job for reasons unrelated to AI—promotion, career change, layoffs from business performance. Hazard models can incorporate competing risks that affect your probability of remaining in the "at risk" population.</li>
                        </ul>

                        <p><strong>What hazard models don't capture:</strong> No model captures everything. Hazard models assume that displacement risk follows certain statistical patterns, which may not hold if AI progress is discontinuous or if organizational adoption happens in sudden waves rather than gradual shifts. They also assume that the factors we measure (hierarchy, task structure, domain friction) are the ones that matter most for your specific situation.</p>

                        <p>The model is best understood as a structured way to reason about probability under uncertainty, not as a prediction machine. It makes your assumptions explicit and shows their implications—but the assumptions themselves come from empirical trends that could shift.</p>

                        <h3>Model limitations and uncertainties</h3>

                        <p>Understanding where the model breaks down is as important as understanding how it works. The following limitations should inform how you interpret and use the results.</p>

                        <p><strong>Assumption of smooth capability growth:</strong> The model assumes AI capability continues doubling on a predictable exponential curve. Real progress may be discontinuous. A single algorithmic breakthrough (like a major advance in reasoning, planning, or tool use) could compress what the model projects as 5 years of progress into 6 months. Conversely, capability growth could plateau if current scaling approaches hit fundamental limits or if compute investment slows more dramatically than expected. The METR trend line is calibrated on historical data, but the future is not guaranteed to follow the past.</p>

                        <p><strong>Single-path assumption:</strong> The hazard model assumes displacement happens through the channels modeled: direct automation and workforce compression. It doesn't capture other pathways like company-level failure (your entire organization goes under due to competitive pressure from AI-augmented competitors), industry collapse (your entire sector becomes economically unviable), or policy intervention (regulations mandate human-in-the-loop for your domain). These factors could dominate individual displacement risk but operate at different levels of analysis.</p>

                        <p><strong>Static organizational behavior:</strong> The model treats organizational adoption as following predictable friction curves. Real companies are messier. A leadership change, merger, financial crisis, or strategic pivot can instantly change adoption appetite in ways the questionnaire can't anticipate. Conversely, deep cultural resistance or regulatory capture might create barriers far beyond what the friction parameters suggest. The model averages across organizations; your specific employer may be an outlier.</p>

                        <p><strong>Task decomposition uncertainty:</strong> The model requires mapping your job onto five task duration buckets. This decomposition is inherently subjective and imprecise. Many jobs blend short and long-horizon work in ways that don't fit cleanly into buckets. The questionnaire tries to capture task distribution through proxy questions, but the mapping from questionnaire responses to actual time allocation is approximate. Two people with similar questionnaire answers might have meaningfully different task portfolios.</p>

                        <p><strong>Domain friction calibration:</strong> The domain friction multipliers (software engineering 1.05×, legal 1.45×, etc.) are informed estimates rather than empirically calibrated values. We don't yet have enough real-world AI deployment data to precisely measure how automation difficulty varies across domains. The multipliers reflect expert judgment about relative difficulty, but the absolute values could be significantly off. A 1.45× multiplier might really be 1.2× or 1.8× for your specific legal role.</p>

                        <p><strong>Compression threshold assumptions:</strong> The model assumes compression hazard activates when AI reaches 33% job readiness and seniors can reallocate 70% of their time amplified by AI. These thresholds are plausible but not empirically validated. Real compression might require higher or lower capability levels depending on organizational structure, span of control, and how work actually flows through your company. The 33% threshold is a modeling choice, not an observed fact.</p>

                        <p><strong>Re-employment modeling:</strong> The re-employment probability calculation is particularly uncertain because it depends on future labor market conditions we can't observe. The model incorporates your transferable skills and adaptability, but it can't account for how many other displaced workers will compete for similar roles, whether new job categories will emerge, or how quickly adjacent industries will also face automation pressure. The re-employment estimates should be understood as relative rankings (higher vs. lower probability) rather than precise forecasts.</p>

                        <h3>Sensitivity analysis: What matters most</h3>

                        <p>Not all parameters affect outcomes equally. Sensitivity testing reveals which assumptions have the largest impact on your displacement timeline:</p>

                        <ul class="detail-list">
                            <li><strong>Capability doubling time (highest impact):</strong> Changing the doubling time from 7 months to 4 months can shift displacement timelines 2-3 years earlier. Conversely, if doubling slows to 12 months, timelines extend by 3-5 years. This parameter dominates all others because it controls the pace at which AI clears task gates. Small changes here produce large timeline shifts.</li>
                            <li><strong>Hierarchy level (high impact for compression):</strong> Moving from Level 1 to Level 3 typically adds 2-4 years to your compression timeline by reducing hierarchy vulnerability from 100% to 60%. This matters most for roles where compression is the dominant hazard channel. For roles where direct automation dominates, hierarchy has less effect.</li>
                            <li><strong>Domain friction multiplier (moderate impact):</strong> Changing your domain multiplier by 0.3× (e.g., from 1.2× to 1.5×) shifts automation timelines by roughly 1-2 years. This parameter sets how long AI needs to develop before it can handle your domain, but it doesn't affect the underlying growth rate.</li>
                            <li><strong>Organizational adoption parameters (moderate impact):</strong> Aggressive vs. defensive company culture can shift implementation timelines by 1-3 years via the initial delay parameter. However, friction decay eventually collapses these differences, so the impact diminishes over longer time horizons.</li>
                            <li><strong>Task distribution (low to moderate impact):</strong> Shifting task concentration from short to long horizons (e.g., answering Q5/Q6 differently) changes which capability gates matter, typically shifting timelines by 6 months to 2 years depending on how extreme the shift is.</li>
                            <li><strong>Reliability threshold (low impact on ranking):</strong> Requiring 99% vs. 95% reliability delays automation by roughly 1-2 years across all roles. This shifts everyone's timeline proportionally, so it matters more for absolute timing than relative ranking.</li>
                        </ul>

                        <p>Use these sensitivity rankings to focus your attention. If you're trying to assess your true risk, verify your assumptions about capability doubling time and hierarchy level first—these drive the largest uncertainty. Parameters like reliability threshold and minor questionnaire adjustments matter less.</p>

                        <h3>Calibration and validation challenges</h3>

                        <p>Unlike models in established fields with decades of data, AI displacement forecasting operates without a robust empirical base. We can't directly validate the model's predictions because large-scale AI-driven job displacement hasn't happened yet. The model rests on several types of evidence, each with limitations:</p>

                        <p><strong>METR benchmark data:</strong> Provides solid empirical grounding for capability growth rates. However, benchmarks measure software engineering tasks specifically. The translation to other domains (legal, consulting, creative work) relies on assumptions about domain similarity that can't be directly tested until AI actually attempts those tasks at scale.</p>

                        <p><strong>Historical precedents:</strong> Previous automation waves (spreadsheets, CAD, ATMs) inform our understanding of compression dynamics and organizational friction. But AI differs in scope (affects nearly all cognitive work simultaneously) and pace (capability doubles every 7 months vs. slower technology diffusion in past waves). Historical patterns may not hold.</p>

                        <p><strong>Expert judgment:</strong> Many parameters (domain friction multipliers, compression thresholds, task decomposition weights) come from expert assessment rather than data. These represent informed estimates, but they're fundamentally guesses about how automation difficulty varies across contexts.</p>

                        <p><strong>Lack of negative cases:</strong> We have abundant data on AI capabilities growing and some early signals of workforce compression (e.g., content moderation, customer support). We have almost no data on situations where automation plateaued, where organizational adoption stalled permanently, or where friction proved insurmountable. The model may underweight barriers we haven't yet encountered.</p>

                        <p>As real-world AI deployment scales and actual displacement data becomes available, calibration will improve. For now, treat the model as a framework for structured thinking rather than a validated predictive instrument.</p>

                        <h3>Edge cases and when the model breaks</h3>

                        <p><strong>Very senior / unique roles:</strong> For Level 4-5 positions with highly specialized expertise, the compression channel essentially turns off (few people above to absorb work), and automation timelines extend far enough that the model's projections become highly speculative. These roles may face displacement through paths the model doesn't capture (entire company restructuring, industry collapse, emergence of entirely new AI paradigms).</p>

                        <p><strong>Highly regulated domains:</strong> Healthcare, legal services, financial advising, and other heavily regulated fields may face non-technical barriers (liability, licensing requirements, professional ethics) that aren't captured by domain friction alone. The model treats regulation as a friction multiplier, but in practice regulatory barriers might create hard stops rather than delays.</p>

                        <p><strong>Roles with strong human-relationship requirements:</strong> Therapists, executive coaches, clergy, and other relationship-dependent roles face displacement dynamics that don't map well onto task automation. The value isn't just in outputs delivered but in the human connection itself. The model can't adequately represent this dimension.</p>

                        <p><strong>Discontinuous capability jumps:</strong> If AI suddenly achieves step-function improvements (e.g., robust long-horizon planning, true multimodal reasoning, human-level creativity), the smooth capability curves become invalid. The model would underestimate displacement timelines if capability growth is slower than exponential, and dramatically overestimate runways if capability jumps happen.</p>

                        <p><strong>Economic disruption scenarios:</strong> If AI-driven productivity gains trigger macroeconomic disruption (mass unemployment, demand collapse, policy intervention), individual displacement timelines become less relevant than systemic dynamics. The model assumes the broader economy continues functioning; if that assumption fails, the outputs are no longer meaningful.</p>

                        <p>Recognize these boundaries. The model works best for mid-hierarchy knowledge workers in moderately regulated domains where work can be digitized and AI capability is growing smoothly. Outside these conditions, use the model's framework but hold the quantitative outputs lightly.</p>

                        <h3>Model Flow: How Your Inputs Become Predictions</h3>

                        <div style="margin: 24px 0; padding: 20px; background: #fdfaf5; border-radius: 12px; border: 1px solid #e6dcc8; overflow-x: auto;">
                            <svg id="model-flow-diagram" viewBox="0 0 1000 800" style="width: 100%; min-width: 600px; height: auto; margin: 0 auto; display: block;">
                                <!-- Define styles -->
                                <defs>
                                    <style>
                                        .flow-box { transition: all 0.3s ease; cursor: pointer; }
                                        .flow-box:hover rect { fill: #fdf7ed; stroke: #a88860; stroke-width: 2.5; }
                                        .flow-arrow { transition: all 0.3s ease; }
                                        .input-box rect { fill: #f5f1ea; stroke: #9b8b6f; }
                                        .calc-box rect { fill: #fdfaf5; stroke: #d2c7b8; }
                                        .output-box rect { fill: #f0f7f4; stroke: #7fa89b; }
                                        .blue-output rect { fill: #e8f1f8; stroke: #5a8db8; }
                                        .green-output rect { fill: #e8f5ee; stroke: #6ba583; }
                                    </style>
                                </defs>

                                <!-- Title -->
                                <text x="500" y="40" text-anchor="middle" font-family="'Inter', sans-serif" font-size="24" font-weight="600" fill="#495057">Your Inputs → Calculations → Results</text>

                                <!-- LEVEL 1: INPUTS -->
                                <g class="flow-box input-box" data-connects="task-dist,auto-timing,comp-timing">
                                    <rect x="50" y="90" width="280" height="120" rx="8" stroke-width="1.5"/>
                                    <text x="190" y="120" text-anchor="middle" font-family="'Inter', sans-serif" font-size="17" font-weight="600" fill="#2a5298">Questionnaire</text>
                                    <text x="190" y="143" text-anchor="middle" font-size="13" fill="#495057">Your answers to Q1-Q19</text>
                                    <text x="190" y="163" text-anchor="middle" font-size="11" fill="#868e96">AI capability, task characteristics,</text>
                                    <text x="190" y="178" text-anchor="middle" font-size="11" fill="#868e96">friction factors, and adaptability</text>
                                    <text x="190" y="193" text-anchor="middle" font-size="11" fill="#868e96">questions that shape all outputs</text>
                                </g>

                                <g class="flow-box input-box" data-connects="task-dist,comp-timing">
                                    <rect x="360" y="90" width="260" height="120" rx="8" stroke-width="1.5"/>
                                    <text x="490" y="120" text-anchor="middle" font-family="'Inter', sans-serif" font-size="17" font-weight="600" fill="#2a5298">Hierarchy Level</text>
                                    <text x="490" y="143" text-anchor="middle" font-size="13" fill="#495057">Level 1-5</text>
                                    <text x="490" y="163" text-anchor="middle" font-size="11" fill="#868e96">Position in organizational ladder.</text>
                                    <text x="490" y="178" text-anchor="middle" font-size="11" fill="#868e96">Affects compression vulnerability</text>
                                    <text x="490" y="193" text-anchor="middle" font-size="11" fill="#868e96">and task distribution patterns</text>
                                </g>

                                <g class="flow-box input-box" data-connects="auto-timing">
                                    <rect x="650" y="90" width="300" height="120" rx="8" stroke-width="1.5"/>
                                    <text x="800" y="120" text-anchor="middle" font-family="'Inter', sans-serif" font-size="17" font-weight="600" fill="#2a5298">Sliders</text>
                                    <text x="800" y="143" text-anchor="middle" font-size="13" fill="#495057">Reliability and Industry Friction</text>
                                    <text x="800" y="163" text-anchor="middle" font-size="11" fill="#868e96">Adjusts how strict automation needs</text>
                                    <text x="800" y="178" text-anchor="middle" font-size="11" fill="#868e96">to be (reliability) and how much harder</text>
                                    <text x="800" y="193" text-anchor="middle" font-size="11" fill="#868e96">your industry is to automate (friction)</text>
                                </g>

                                <!-- LEVEL 2: CALCULATIONS -->
                                <g id="task-dist" class="flow-box calc-box" data-connects="blue-output">
                                    <rect x="40" y="270" width="280" height="150" rx="8" stroke-width="1.5"/>
                                    <text x="180" y="300" text-anchor="middle" font-family="'Inter', sans-serif" font-size="16" font-weight="600" fill="#2a5298">Task Distribution</text>
                                    <text x="180" y="330" text-anchor="middle" font-size="12" fill="#495057">How your job splits across 5 task</text>
                                    <text x="180" y="348" text-anchor="middle" font-size="12" fill="#495057">duration buckets (short to long)</text>
                                    <text x="180" y="375" text-anchor="middle" font-size="11" fill="#868e96">Hierarchy level, Q5 (decomposability),</text>
                                    <text x="180" y="393" text-anchor="middle" font-size="11" fill="#868e96">Q6 (standardization), Q7 (context)</text>
                                    <text x="180" y="413" text-anchor="middle" font-size="10" font-style="italic" fill="#a88860">Can override manually in calculator</text>
                                </g>

                                <g id="auto-timing" class="flow-box calc-box" data-connects="blue-output,green-output">
                                    <rect x="360" y="270" width="280" height="150" rx="8" stroke-width="1.5"/>
                                    <text x="500" y="300" text-anchor="middle" font-family="'Inter', sans-serif" font-size="16" font-weight="600" fill="#2a5298">Automation Timing</text>
                                    <text x="500" y="330" text-anchor="middle" font-size="12" fill="#495057">When AI becomes technically capable</text>
                                    <text x="500" y="348" text-anchor="middle" font-size="12" fill="#495057">of doing your job (blue curve basis)</text>
                                    <text x="500" y="375" text-anchor="middle" font-size="11" fill="#868e96">Task buckets, reliability slider,</text>
                                    <text x="500" y="393" text-anchor="middle" font-size="11" fill="#868e96">industry friction, Q2/Q6-Q16</text>
                                </g>

                                <g id="comp-timing" class="flow-box calc-box" data-connects="green-output">
                                    <rect x="680" y="270" width="280" height="150" rx="8" stroke-width="1.5"/>
                                    <text x="820" y="300" text-anchor="middle" font-family="'Inter', sans-serif" font-size="16" font-weight="600" fill="#2a5298">Compression Risk</text>
                                    <text x="820" y="330" text-anchor="middle" font-size="12" fill="#495057">Job loss from task reallocation to</text>
                                    <text x="820" y="348" text-anchor="middle" font-size="12" fill="#495057">AI-amplified seniors (green modifier)</text>
                                    <text x="820" y="375" text-anchor="middle" font-size="11" fill="#868e96">Q10 (reallocation ease), Q4-Q9</text>
                                    <text x="820" y="393" text-anchor="middle" font-size="11" fill="#868e96">(AI learnability), hierarchy vulnerability</text>
                                </g>

                                <!-- LEVEL 3: OUTPUTS -->
                                <g id="blue-output" class="flow-box blue-output">
                                    <rect x="80" y="490" width="380" height="160" rx="8" stroke-width="1.5"/>
                                    <text x="270" y="520" text-anchor="middle" font-family="'Inter', sans-serif" font-size="16" font-weight="600" fill="#2a5298">Blue Curve</text>
                                    <text x="270" y="543" text-anchor="middle" font-size="13" fill="#495057">Timeline estimation of your role's</text>
                                    <text x="270" y="560" text-anchor="middle" font-size="13" fill="#495057">technical automation feasibility</text>
                                    <text x="270" y="583" text-anchor="middle" font-size="11" fill="#868e96">When AI becomes capable enough to</text>
                                    <text x="270" y="598" text-anchor="middle" font-size="11" fill="#868e96">perform your job, based on METR's task</text>
                                    <text x="270" y="613" text-anchor="middle" font-size="11" fill="#868e96">horizon data, your task distribution, and</text>
                                    <text x="270" y="628" text-anchor="middle" font-size="11" fill="#868e96">reliability/friction settings</text>
                                </g>

                                <g id="green-output" class="flow-box green-output">
                                    <rect x="540" y="490" width="380" height="160" rx="8" stroke-width="1.5"/>
                                    <text x="730" y="520" text-anchor="middle" font-family="'Inter', sans-serif" font-size="16" font-weight="600" fill="#6ba583">Green Curve</text>
                                    <text x="730" y="543" text-anchor="middle" font-size="13" fill="#495057">Timeline estimation of your</text>
                                    <text x="730" y="560" text-anchor="middle" font-size="13" fill="#495057">actual role elimination</text>
                                    <text x="730" y="583" text-anchor="middle" font-size="11" fill="#868e96">When job loss actually happens in practice.</text>
                                    <text x="730" y="598" text-anchor="middle" font-size="11" fill="#868e96">Combines blue curve + implementation</text>
                                    <text x="730" y="613" text-anchor="middle" font-size="11" fill="#868e96">delay + compression hazard. Can arrive</text>
                                    <text x="730" y="628" text-anchor="middle" font-size="11" fill="#868e96">earlier than blue if compression is high</text>
                                </g>

                                <!-- ARROWS: Inputs to Calculations -->
                                <path class="flow-arrow" d="M 190 210 L 180 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 230 210 L 500 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 260 210 L 820 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

                                <path class="flow-arrow" d="M 490 210 L 220 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 510 210 L 800 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

                                <path class="flow-arrow" d="M 800 210 L 530 270" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

                                <!-- ARROWS: Calculations to Outputs -->
                                <path class="flow-arrow" d="M 180 420 L 230 490" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 500 420 L 320 490" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 500 420 L 680 490" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                                <path class="flow-arrow" d="M 820 420 L 770 490" stroke="#9b8b6f" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

                                <!-- Arrow markers -->
                                <defs>
                                    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                                        <polygon points="0 0, 10 3, 0 6" fill="#9b8b6f"/>
                                    </marker>
                                </defs>

                                <!-- Legend -->
                                <g transform="translate(60, 690)">
                                    <text x="0" y="0" font-family="'Inter', sans-serif" font-size="12" font-weight="600" fill="#2a5298">Legend:</text>
                                    <rect x="0" y="12" width="20" height="20" rx="2" fill="#f5f1ea" stroke="#9b8b6f" stroke-width="1.5"/>
                                    <text x="26" y="26" font-size="11" fill="#495057">Your inputs</text>

                                    <rect x="140" y="12" width="20" height="20" rx="2" fill="#fdfaf5" stroke="#d2c7b8" stroke-width="1.5"/>
                                    <text x="166" y="26" font-size="11" fill="#495057">Calculations</text>

                                    <rect x="280" y="12" width="20" height="20" rx="2" fill="#e8f1f8" stroke="#5a8db8" stroke-width="1.5"/>
                                    <text x="306" y="26" font-size="11" fill="#495057">Blue curve</text>

                                    <rect x="410" y="12" width="20" height="20" rx="2" fill="#e8f5ee" stroke="#6ba583" stroke-width="1.5"/>
                                    <text x="436" y="26" font-size="11" fill="#495057">Green curve</text>

                                    <text x="560" y="26" font-size="11" fill="#868e96" font-style="italic">Hover over boxes to highlight connections</text>
                                </g>

                                <!-- Key insights -->
                                <g transform="translate(60, 760)">
                                </g>
                            </svg>
                        </div>

                        <script>
                            // Simple hover interactions for the model flow diagram
                            document.addEventListener('DOMContentLoaded', function() {
                                const flowBoxes = document.querySelectorAll('.flow-box');

                                flowBoxes.forEach(box => {
                                    box.addEventListener('mouseenter', function() {
                                        const connects = this.getAttribute('data-connects');
                                        if (connects) {
                                            connects.split(',').forEach(targetId => {
                                                const target = document.getElementById(targetId);
                                                if (target) {
                                                    target.querySelector('rect').style.fill = '#fdf7ed';
                                                    target.querySelector('rect').style.stroke = '#a88860';
                                                    target.querySelector('rect').style.strokeWidth = '2.5';
                                                }
                                            });
                                        }
                                    });

                                    box.addEventListener('mouseleave', function() {
                                        const connects = this.getAttribute('data-connects');
                                        if (connects) {
                                            connects.split(',').forEach(targetId => {
                                                const target = document.getElementById(targetId);
                                                if (target) {
                                                    // Reset to original colors based on box type
                                                    const rect = target.querySelector('rect');
                                                    if (target.classList.contains('calc-box')) {
                                                        rect.style.fill = '#fdfaf5';
                                                        rect.style.stroke = '#d2c7b8';
                                                    } else if (target.classList.contains('blue-output')) {
                                                        rect.style.fill = '#e8f1f8';
                                                        rect.style.stroke = '#5a8db8';
                                                    } else if (target.classList.contains('green-output')) {
                                                        rect.style.fill = '#e8f5ee';
                                                        rect.style.stroke = '#6ba583';
                                                    }
                                                    rect.style.strokeWidth = '1.5';
                                                }
                                            });
                                        }
                                    });
                                });
                            });
                        </script>

                        <h3 class="h3-accent">Model Defaults</h3>
                        <div class='bubble-table'>
                            <div class='bubble-item'><span class='bubble-key'>$H_{50,0}$</span><span class='bubble-val'>~162 min (GPT-5.1-Codex-Max SOTA)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$D$ (doubling, months)</span><span class='bubble-val'>~6-7 (computed from METR data)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$r$ (reliability)</span><span class='bubble-val'>0.95 (default)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$L_i$ (gate thresholds)</span><span class='bubble-val'>5, 30, 120, 360, 720 min</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$w_i$ (weights)</span><span class='bubble-val'>15%, 30%, 30%, 15%, 10%</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$s$ (softness)</span><span class='bubble-val'>0.35 (lower = sharper transition; range 0.20&ndash;0.55)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$h_{\text{AI}}$ (max hazard)</span><span class='bubble-val'>0.45/yr</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$\gamma$ (steepness)</span><span class='bubble-val'>8.0</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$\theta$ (threshold)</span><span class='bubble-val'>0.50</span></div>
                            <div class='bubble-item'><span class='bubble-key'>userMult range</span><span class='bubble-val'>0.33&times; to 3.0&times;</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$t$ (timeline)</span><span class='bubble-val'>Years from now</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$H_r(t)$</span><span class='bubble-val'>Task horizon at reliability $r$</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$A_{\text{job}}$</span><span class='bubble-val'>Readiness &isin; [0,1]</span></div>
                            <div class='bubble-item'><span class='bubble-key'>$f(r)$</span><span class='bubble-val'>Reliability factor</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Task buckets</span><span class='bubble-val'>&lt;10 min, 10-45 min, 45 min-3 hr, 3-8 hr, &gt;12 hr</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Hazard floor</span><span class='bubble-val'>0.03/yr minimum risk</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Hazard cap</span><span class='bubble-val'>0.95/yr ceiling after multipliers</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Domain clamp</span><span class='bubble-val'>Penalty clamped to 0.8&ndash;1.6&times;</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Compression: readiness mix</span><span class='bubble-val'>70% immediate / 30% amplified</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Compression: cap gain</span><span class='bubble-val'>1.04 (scales with $A_{\text{job}}$)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Compression: floor</span><span class='bubble-val'>0.15 (min $A_{\text{job}}$ to activate)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Compression: amp</span><span class='bubble-val'>2.0 (max productivity boost)</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Compression: gate</span><span class='bubble-val'>$\theta_c$=0.33, $\gamma_c$=6.0, $h_{\max,c}$=0.45/yr</span></div>
                        </div>

                        <h3 class="h3-accent">Friction Decay Parameter</h3>
                        <p>The model tracks how quickly organizational barriers weaken over time using a decay rate (&lambda;). This parameter is calculated from your questionnaire responses about company adoption readiness, infrastructure, labor market dynamics, and role characteristics:</p>
                        <div class='equation-callout'>
                            <span class='callout-label'>Friction decay rate</span>
                            <div class='equation-display'>$$\lambda = 0.02 + 0.01 \times (n_{12} - 0.5) + 0.01 \times (n_{15} - 0.5) + 0.005 \times (n_{13} - 0.5) + 0.005 \times (n_{14} - 0.5) - 0.01 \times (n_{11} - 0.5) - 0.01 \times (n_{10} - 0.5)$$</div>
                            <p style="font-size: 0.9em; margin-top: 8px; color: #666;">where $n_i$ is the normalized answer to question $i$ (Likert 1-5 scaled to 0-1), and $\lambda$ is clamped to $[0.005, 0.05]$</p>
                        </div>
                        <div class='bubble-table'>
                            <div class='bubble-item'><span class='bubble-key'>Q12 (Physical presence)</span><span class='bubble-val'>+0.01 weight</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Q15 (Labor market tightness)</span><span class='bubble-val'>+0.01 weight</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Q13 (Company AI adoption)</span><span class='bubble-val'>+0.005 weight</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Q14 (Labor cost pressure)</span><span class='bubble-val'>+0.005 weight</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Q11 (Human judgment)</span><span class='bubble-val'>-0.01 weight</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Q10 (Task reallocation)</span><span class='bubble-val'>-0.01 weight</span></div>
                        </div>
                        <p>This parameter controls how quickly implementation barriers shrink as AI capability grows. The model implements dynamic friction decay where implementation delay decreases exponentially: $\Delta(t) = \Delta_0 \cdot e^{-\lambda t}$. At time $t$, the green curve (actual job loss) equals technical feasibility at the earlier time $t - \Delta(t)$. Higher $\lambda$ means barriers collapse faster once AI crosses initial thresholds, while lower $\lambda$ means barriers persist even as capability advances. This captures how regulatory frameworks and organizational inertia may initially delay adoption by several years, though these delays shrink as AI improves and more companies adopt it.</p>
                        <p>The decay accelerates once $\lambda$ exceeds 0.025 (the knee point). Two additional parameters shape the dynamics: a saturation boost (0.6) that amplifies decay as capability matures, and a capability gain factor (0.8) that links delay compression to job readiness growth. Together these determine how quickly barriers collapse once AI capability and organizational readiness combine.</p>

                        <h3 class="h3-accent">Role Presets</h3>
                        <p>Different roles face different automation barriers. Software engineering maps most directly to AI's training data and requires less physical presence, so it gets lower friction (1.05x). Legal work and traditional engineering involve more tacit knowledge, regulatory constraints, and liability concerns, earning higher friction multipliers (1.45–1.50x). These multipliers reflect how much harder it is to automate each domain compared to software.</p>
                        <p><strong>Two-layer friction system:</strong> Industry friction applies to all roles in a sector (e.g., finance ~1.35×), while your questionnaire adds role-specific friction from tacit knowledge, physical presence, and context. Both layers multiply together (friction presets widen the domain clamp, but capability doubling stays from METR).</p>
                        <ul class='detail-list'>
                            <li><strong>Domain friction (preset baseline):</strong> Role presets set an initial friction multiplier (software ~1.05x, admin/data ~1.10x, finance/consulting ~1.35x, legal ~1.45x, engineering ~1.50x) before individual job characteristics are considered.</li>
                            <li><strong>Recommended reliability:</strong> Presets suggest a reliability starting point per role based on typical error tolerance and stakes (finance/legal 97&ndash;98%, software/data 92&ndash;93%, creative/customer service 88&ndash;90%). Seniority adjusts these baselines: entry-level roles tolerate slightly lower reliability (&minus;0.05), while executive decisions demand higher confidence (+0.05). Higher reliability requirements significantly reduce effective task horizon. You can override both friction and reliability in the UI to test different scenarios.</li>
                        </ul>
                        <p>Beyond the preset baseline, the calculator derives a role-specific <em>domain alignment</em> penalty from your answers. Digitized, decomposable, and standardized work (Q4/Q5/Q6 high) reduces the penalty, while context dependence, tacit knowledge, judgment/relationship load, and physical presence (Q7/Q9/Q11/Q12 high) increase it. The model forms a signed weighted sum and maps it to a penalty multiplier via an exponential, clamped to a reasonable range. This penalty multiplies with the sector slider, so domain misalignment adds to friction.</p>
                        <div class='equation-callout'>
                            <span class='callout-label'>AI hazard core</span>
                            <div class='equation-display'>$$\lambda_{\text{AI}}(s) = \frac{h_{\max}}{1 + \exp\!\big(-\gamma (A_{\text{job}}(s) - \theta)\big)} \cdot M_{\text{user}}(s)$$</div>
                        </div>
                        <p>The hazard activates once AI capability crosses a coverage threshold. Two gates control this: task-level gates determine which individual tasks AI can handle, while a job-level gate opens when enough of your job is automatable to justify replacement. Here's the sequence:</p>
                        <ol class='action-list'>
                            <li><strong>Task-level gates open gradually:</strong> As AI capability $H_r(t)$ grows via METR's doubling trend, each task bucket's gate $G_i(H)$ opens. Short tasks automate first (gates open when $H$ exceeds their threshold $L_i$), then medium tasks, then long tasks. Your personalized weights $w_i$ determine how much each gate contributes to overall readiness.</li>
                            <li><strong>Job readiness accumulates:</strong> $A(t) = \sum w_i G_i(H)$ sums up all the open gates, weighted by your job profile. This gives a number between 0 and 1 representing what fraction of your job AI can perform.</li>
                            <li><strong>Job-level hazard gate activates:</strong> When $A(t)$ crosses the coverage threshold $\theta$ (typically 0.50), the hazard function $\lambda_{\text{AI}}(t)$ rapidly increases via the logistic gate. Before this point, hazard is near zero; after, it approaches the maximum $h_{\max} \times M_{\text{user}}$.</li>
                        </ol>
                        <div class='equation-callout'>
                            <span class='callout-label'>Task horizon</span>
                            <div class='equation-display'>$$H_r(t) = \frac{H_{50,0} \cdot 2^{(t \cdot 12)/D}}{p_{\text{domain}} \cdot f_{\text{industry}} \cdot f(r)}$$</div>
                            <p style="font-size: 0.9em; margin-top: 8px; color: #666;">where $p_{\text{domain}}$ = role-specific penalty from questionnaire, $f_{\text{industry}}$ = industry friction slider</p>
                        </div>
                        <p>The numerator's exponential term $2^{(t \cdot 12)/D}$ doubles roughly every 6–7 months per METR data—this is the capability growth. Domain friction, industry friction, and the reliability penalty are constant divisors that scale down this baseline; they don't affect the growth rate, only the starting point.</p>
                        <p>Reliability penalty: $\;f(r)=e^{-\sigma \cdot \text{logit}(r)}$ with $\sigma = \ln(H_{80}/H_{50}) / \ln(4)$. At 95% reliability, $f(r)\approx 33.4$, so the median 162-minute horizon becomes ~4.8 minutes of production-ready work.</p>
                        <p>Domain penalty: weighted Q4/5/6 (−) vs Q7/9/11/12 (+) → exponential penalty clamped (default 0.8–1.6×; widened by friction presets). Industry slider multiplies on top. Neutral answers include a modest baseline bias (~1.2×) before clamping to reflect average domain mismatch.</p>
                        <ul class='detail-list'>
                            <li><strong>Personalized task weights $w_i$:</strong> Your answers to Q5 (task decomposability), Q6 (task standardization), Q7 (context dependency), and your hierarchy level determine how your job breaks down across the five buckets. Entry-level roles skew toward shorter tasks; executive roles skew toward longer tasks. Highly structured jobs concentrate weight in the short buckets; complex jobs shift weight to longer buckets. High-context work means more weight in the 1&ndash;3 hr and &gt;12 hr buckets. The weights always sum to 1.0 and represent what fraction of your job falls into each duration category.</li>
                            <li><strong>Gate softness parameter $s$:</strong> Controls how sharply tasks transition from "AI can't do this" to "AI can do this". Entry-level structured work has sharper transitions; senior complex work has smoother, more gradual automation curves. Base value is 0.35, adjusted by seniority (&pm;0.03 per level) and task complexity (Q5, Q6). Range: [0.20, 0.55].</li>
                            <li><strong>Readiness $A_{\text{job}}(t)$:</strong> $$A_{\text{job}}(t) = \sum_i w_i G_i(H_r(t))$$ This weighted sum tells us what fraction of your job AI can perform at time $t$. If you're an entry-level role with 40% of tasks under 5 minutes and AI's capability $H_r(t)$ has reached 10 minutes, the &lt;5 min gate is fully open ($G_1 \approx 1.0$), contributing $0.40 \times 1.0 = 0.40$ to readiness. Jobs with more long-duration tasks need higher $H_r$ before their readiness $A(t)$ crosses the coverage threshold $\theta$, delaying automation.</li>
                            <li><strong>Coverage bar $\theta$:</strong> Baseline is 0.50, adjusted by seniority (thetaLift from -0.015 to +0.040), domain alignment (coefficient 0.09, ~&pm;0.09 at extremes), and role explicitness (coefficient 0.08, ~&pm;0.08 at extremes). Data-rich jobs, standardized workflows, and fast feedback loops lower this threshold; tacit, high-context, and senior roles push it higher. Clamped to [0.50, 0.82]. This threshold controls how much of the job must be automatable before displacement risk activates.</li>
                            <li><strong>User multipliers $M_{\text{user}}(s)$:</strong> Questionnaire responses exponentiate into amplifier and friction sums, then are capped between $0.33\times$ and $3\times$ for responsiveness.</li>
                        </ul>
                    </section>

                    <section>
                        <h2>How your answers move the curve</h2>
                        <p>Your answers (on a 1–5 Likert scale) are converted so that neutral (3) maps to 0, allowing symmetric effects above and below the midpoint. The model combines these into amplifier and friction scores, then converts them to multipliers ranging from 0.33&times; to 3.0&times;.</p>
                        <p>The prompts fall into four themes:</p>
                        <ul class='detail-list'>
                            <li><strong>AI readiness (Q1-Q4):</strong> High scores strengthen the amplifier channel when you indicate strong capability for AI learning and completing your tasks. Additionally, Q1 (current AI performance), Q2 (example work availability), Q3 (benchmark clarity), and Q4 (work digitization) all contribute to role explicitness ($s_e$), which lowers the coverage threshold $\theta$, making automation viable at lower overall capability levels.</li>
                            <li><strong>Task structure (Q5&ndash;Q9):</strong> These questions affect the blue curve (technical feasibility) through multiple mechanisms: <strong>(1)</strong> Q5, Q6 shift the task duration profile (structured &rarr; shorter buckets, complex &rarr; longer buckets), <strong>(2)</strong> Q2, Q5, Q6, Q8 contribute to $s_e$ which <strong>lowers $\theta$</strong> (data-rich, decomposable, standardized, fast-feedback jobs become viable at lower capability), and <strong>(3)</strong> Q7, Q9 increase the domain penalty $p_{\text{domain}}$ (high context, tacit knowledge damp capability). Together, these determine when your specific job crosses the automation threshold.</li>
                            <li><strong>Human moat (Q11-Q12):</strong> Relationship intensity and physical presence both load the friction side and stretch the METR baseline via the domain penalty, pushing the curve out.</li>
                            <li><strong>Firm and personal context (Q13-Q19):</strong> Company levers shape implementation delay. Job performance (Q19) delays displacement for top performers while also helping re-employment. Adaptability (Q18) and transferability (Q17) drive re-employment probability.</li>
                        </ul>
                        <p><strong>How role clarity affects the threshold:</strong> Questions Q1, Q2, Q3, Q4, Q5, Q6, and Q8 (positive factors) are averaged together, while Q7 and Q9 (context dependency and tacit knowledge, the protective factors) are averaged separately. The formula $s_e = 0.65 \times \text{norm}(s_{\text{pos}}) - 0.35 \times \text{norm}(s_{\text{neg}}) + 0.10$ produces a score between 0 and 1. Higher scores (more explicit roles) reduce $\theta$ via the shift $\Delta_{s_e} = 0.10 \times (0.5 - s_e)$, meaning AI needs less total job coverage before automation becomes economically viable.</p>

                        <p>The model also adjusts how sharply the hazard ramps up ($\gamma$) based on task characteristics. Structured work, fast feedback, and standardized tasks make the transition sudden; messy, collaborative, or custom work makes it gradual. This affects whether adoption happens quickly once the threshold is crossed or drags out over years.</p>
                    </section>

                    <section>
                        <h2>The green curve: Implementation delay and workforce compression</h2>

                        <p>The green curve (actual job loss) differs from the blue curve (technical feasibility) through two mechanisms: organizational adoption barriers that delay automation, and compression-driven workforce reductions that can cause job loss earlier.</p>

                        <h3>How the green curve is calculated</h3>

                        <p>The model integrates two separate hazard channels to create the green curve:</p>

                        <div class='equation-callout'>
                            <span class='callout-label'>Green curve total hazard</span>
                            <div class='equation-display'>$$\lambda_{\text{total}}(t) = \lambda_{\text{AI}}(t - \Delta(t)) + \lambda_{\text{compression}}(t)$$</div>
                            <span class='callout-label'>Where implementation delay decreases over time</span>
                            <div class='equation-display'>$$\Delta(t) = \Delta_0 \cdot e^{-\lambda t}$$</div>
                        </div>

                        <p>This structure captures two different ways jobs disappear:</p>

                        <ul class='detail-list'>
                            <li><strong>Delayed automation hazard:</strong> The AI automation hazard $\lambda_{\text{AI}}$ is evaluated at an earlier time $(t - \Delta(t))$ due to organizational friction. Early in the timeline, implementation barriers create a significant delay ($\Delta_0$), but this delay shrinks exponentially as AI capability grows and adoption accelerates. The friction decay rate $\lambda$ determines how fast these barriers collapse.</li>
                            <li><strong>Compression hazard:</strong> A separate hazard channel $\lambda_{\text{compression}}(t)$ that activates when AI makes senior workers productive enough to absorb junior work. This hazard is evaluated at the current time $t$ (no delay) and can cause job loss well before full automation becomes technically feasible. The two hazards are summed and capped at 0.60/year total.</li>
                        </ul>

                        <h3>Mechanism 1: Implementation delay (shifts automation hazard forward)</h3>

                        <p>Organizational barriers slow AI automation adoption. The initial delay $\Delta_0$ derives from company context (Q13-Q16: adoption appetite, labor cost pressure, market tightness, infrastructure) and individual leverage (Q19: job performance protects top performers). This delay ranges from 0.3 to 4.0 years depending on your situation.</p>

                        <div class='equation-callout'>
                            <span class='callout-label'>Initial delay calculation</span>
                            <div class='equation-display'>$$\Delta_0 = \operatorname{clip}\big(1.75 - 1.25\, s_{\text{delay}} + \Delta^{\text{eff}}_{\text{seniority}},\; 0.3,\; 4.0\big)$$</div>
                            <div class='equation-display'>$$\Delta^{\text{eff}}_{\text{seniority}} = \Delta_{\text{seniority}} \cdot \Big[1 + 0.5\, (\operatorname{norm}(Q19) - 0.5)\, \operatorname{sign}(\Delta_{\text{seniority}})\Big]$$</div>
                            <p style="font-size: 0.9em; margin-top: 8px; color: #666;">$s_{\text{delay}} \in [-2,2]$ from Q13-Q16; $\Delta_{\text{seniority}} \in \{-0.10,-0.03,+0.06,+0.10,+0.12\}$ years by level; result clamped to 0.3–4.0 years</p>
                        </div>

                        <p><strong>Dynamic friction decay:</strong> The delay doesn't stay constant. As AI capability increases and adoption spreads, organizational barriers shrink over time: $\Delta(t) = \Delta_0 \cdot e^{-\lambda t}$. The decay rate $\lambda$ (typically 0.02–0.05/year) is derived from your questionnaire answers (see <em>Friction Decay Parameter</em> above).</p>

                        <p><strong>Example delays:</strong> An early-adopting entry-level role starts with a 0.3-year delay. A defensive environment with senior leadership starts with a 4.0-year delay. Performance (Q19) adjusts these: high performers get extended delays; low performers face shortened timelines.</p>

                        <h3>Mechanism 2: Workforce compression (earlier job loss via task reallocation)</h3>

                        <p>Jobs can be eliminated before AI reaches full automation capability—compression activates at 33% job coverage versus 50% for direct automation. When AI makes senior workers more productive, companies can reduce headcount by redistributing work upward in the hierarchy. An entry-level software engineer's role might disappear when AI can only handle 35% of their tasks, not because AI does everything, but because AI-amplified senior engineers can absorb the remaining 65%.</p>

                        <p><em>For an accessible explanation of why compression happens and how communication overhead drives it, see the <a href="/guide#workforce-compression">Guide's compression section</a>.</em></p>

                        <p>The compression hazard activates earlier and at a lower threshold than full automation. It depends on three factors:</p>

                        <div class='equation-callout'>
                            <span class='callout-label'>Compression hazard (base calculation)</span>
                            <div class='equation-display'>$$\lambda_{\text{compression}}(t) = \frac{h_{\max,c}}{1 + \exp(-\gamma_c (R_c(t) - \theta_c))} \cdot V_{\text{hierarchy}} \cdot G_{\text{readiness}}(t)$$</div>
                            <span class='callout-label'>Where compression readiness uses a hybrid formula with capability scaling:</span>
                            <div class='equation-display'>$$R_c(t) = s_{\text{realloc}} \times \big(0.7 + 0.3(1 + B_{\text{amp}})\big) \times \big(1 + 1.04 \cdot A_{\text{job}}(t)\big)$$</div>
                            <span class='callout-label'>And readiness gate prevents premature compression:</span>
                            <div class='equation-display'>$$G_{\text{readiness}}(t) = \max\Big(0,\, \min\Big(1,\, \frac{A_{\text{job}}(t) - 0.15}{1 - 0.15}\Big)\Big)$$</div>
                            <span class='callout-label'>Amplification boost is:</span>
                            <div class='equation-display'>$$B_{\text{amp}} = f_{\text{effective}} \cdot A_{\text{job}}(t) \cdot \text{norm}(Q1) \cdot 2.0$$</div>
                            <span class='callout-label'>Where effective digital fraction accounts for AI learnability:</span>
                            <div class='equation-display'>$$f_{\text{effective}} = \text{norm}(Q4) \times \max\big(0.1,\, 1 - 0.35\,\text{norm}(Q7) - 0.30\,\text{norm}(Q9) - 0.20\,(1{-}\text{norm}(Q5)) - 0.15\,(1{-}\text{norm}(Q6))\big)$$</div>
                        </div>

                        <p>The <strong>hybrid formula</strong> means compression readiness has two components: 70% comes from reallocation feasibility alone (immediate effect), and 30% grows over time as AI amplifies senior productivity. This ensures Q10 has a noticeable immediate impact while preserving the time-dependent behavior where compression risk accelerates as AI becomes more capable.</p>

                        <p>The <strong>capability scaling factor</strong> $(1 + 1.04 \cdot A_{\text{job}}(t))$ further amplifies compression readiness as AI capability grows. When AI can perform none of your job ($A_{\text{job}} = 0$), the factor is 1.0 (no scaling). When AI can perform your entire job ($A_{\text{job}} = 1$), the factor reaches 2.04, meaning compression readiness roughly doubles at full capability. This captures how organizational willingness to restructure accelerates as AI proves itself capable.</p>

                        <p>The <strong>readiness gate</strong> $G_{\text{readiness}}(t)$ ensures compression hazard remains at zero until AI reaches at least 15% job readiness ($A_{\text{job}} \geq 0.15$), then ramps linearly to full strength by 100% readiness. This prevents spurious compression risk predictions when AI capability is still minimal.</p>

                        <ol class='action-list'>
                            <li><strong>Reallocation feasibility ($s_{\text{realloc}}$):</strong> Combines Q10 (direct reallocation question: <strong>50% weight</strong>), task structure (Q5: 18%, Q6: 12%, Q7: 8% inverted), tacit knowledge (Q9: 10% inverted), and physical presence (Q12: 2% inverted). Q10 is the dominant factor since it directly measures how easily your responsibilities could be redistributed to existing team members. Higher scores mean your work can be easily absorbed by others. Range: [0, 1].</li>
                            <li><strong>Senior productivity amplification ($B_{\text{amp}}$):</strong> AI only amplifies productivity for work that is both digital and AI-learnable. Raw digitization (Q4) is discounted by factors that make digital work harder for AI to learn from: context dependency (Q7: 35% weight), tacit knowledge (Q9: 30% weight), low decomposability (Q5: 20% weight), and low standardization (Q6: 15% weight). A senior consultant whose deliverables are 100% digital but require extensive context, relationships, and tacit judgment gets minimal amplification because while the work is digital, AI cannot learn to replicate it by observing outputs. Conversely, highly digital, standardized, decomposable work with low context enables strong amplification. The boost ranges from 0 to 2.0 (up to +200% output, or 3&times; productivity when used in $(1 + B_{\text{amp}})$), scaled by current AI performance (Q1) and job readiness $A_{\text{job}}(t)$. This factor grows over time as AI capability increases.</li>
                            <li><strong>Hierarchy vulnerability ($V_{\text{hierarchy}}$):</strong> Your position in the workflow determines exposure. Calculated as $(6 - \text{level}) / 5$. Level 1 (many layers above) = 100% vulnerable. Level 4 = 40% vulnerable. Level 5 (top of domain, no one above can do your work) = 20% vulnerable. A principal engineer who owns a system faces minimal compression risk despite being in a "senior" role title.</li>
                        </ol>

                        <p><strong>Parameters differ from full automation:</strong> The compression gate opens at $\theta_c = 0.33$ (vs. $\theta \approx 0.50$ for automation), has gentler slope ($\gamma_c = 6.0$ vs. $\gamma = 8.0$), and equal maximum hazard ($h_{\max,c} = 0.45$/year, matching automation's $h_{\max} = 0.45$/year). For vulnerable positions, AI-driven workforce compression poses significant risk alongside direct automation—earlier onset but more gradual ramp-up. Combined with automation hazard, the total is capped at 0.60/year to reflect real-world institutional friction that prevents instant mass layoffs.</p>

                        <h3>Supporting evidence: Historical precedents for compression</h3>

                        <p>Workforce compression isn't new—every major productivity technology has triggered similar dynamics. Understanding these precedents helps clarify why compression is structural rather than a choice organizations make.</p>

                        <p><strong><a href="https://www.hbs.edu/ris/Publication%20Files/21-050_02b3dec4-b30f-4fd4-aa41-2d6a4933383b.pdf" target="_blank" rel="noopener noreferrer">Spreadsheet case.</a></strong> Before electronic spreadsheets, accounting departments employed armies of clerks to maintain ledgers, perform calculations, and reconcile accounts. A senior accountant might supervise a dozen juniors handling different parts of the books. Spreadsheet software didn't eliminate accounting-it eliminated the need for human calculation. A single accountant with spreadsheet software could handle work that previously required a team. The profession didn't disappear; it compressed. Firms needed fewer total accountants, with survivors handling more complex work.</p>

                        <p><strong><a href="https://www.bls.gov/ooh/architecture-and-engineering/drafters.htm" target="_blank" rel="noopener noreferrer">CAD drafting.</a></strong> Engineering firms once employed large teams of draftsmen who translated engineer sketches into precise technical drawings. Computer-aided design made each engineer self-sufficient for most drafting tasks. The drafting profession didn't vanish entirely, but it shrank significantly as engineers absorbed the work upward, with employment continuing to decline as CAD tools become more sophisticated.</p>

                        <p><strong><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2690435" target="_blank" rel="noopener noreferrer">ATM tellers.</a></strong> The ATM story is often cited as automation creating jobs-bank teller employment actually rose after ATM deployment. But the mechanism matters: ATMs reduced the cost of operating bank branches, so banks opened more branches, which required more tellers. Each branch employed fewer tellers, but there were more branches. This worked because banking services had unmet demand. Knowledge work may not have equivalent untapped demand to absorb productivity gains.</p>

                        <p><strong><a href="https://whattheythink.com/articles/55522-day-typesetting-industry-died/" target="_blank" rel="noopener noreferrer">Desktop publishing.</a></strong> The typesetting profession employed hundreds of thousands of skilled workers who converted manuscripts into printable layouts. Desktop publishing software put that capability in the hands of designers and authors. Typesetting didn't become unimportant-it became absorbed into adjacent roles. The function persisted; the job title disappeared.</p>

                        <p>Across these examples, productivity-enhancing technology compresses workforces when the enhanced workers can absorb the output of their former colleagues. This happens even when everyone becomes more productive, because the organizational need for coordination, review, and integration drops faster than individual output rises.</p>

                        <p><strong>What's different with AI:</strong> Previous compression waves were domain-specific—spreadsheets affected accounting, CAD affected drafting, desktop publishing affected typesetting. AI affects cognitive work across nearly all domains simultaneously. The "absorb upward" dynamic will play out in legal, finance, engineering, marketing, operations, and creative fields at overlapping times. This limits the traditional escape valve of moving to adjacent fields that haven't yet been affected.</p>

                        <h3>The skill degradation trap</h3>

                        <p>A subtler form of compression emerges over time. As AI handles shorter-horizon tasks, humans naturally migrate toward longer-horizon work—strategy, complex problem-solving, judgment calls that require deep context. This seems like a reasonable division of labor.</p>

                        <p>But <a href="https://pubmed.ncbi.nlm.nih.gov/18778378/" target="_blank" rel="noopener noreferrer">skill compounding</a> depends on short-term practice. The senior accountant who reviews complex financial structures developed that judgment by spending years doing basic reconciliations. The strategic consultant who sees patterns across industries built that intuition by doing hundreds of tactical analyses. The architect who designs elegant systems learned what works by debugging messy ones.</p>

                        <p>When we delegate short-horizon tasks to AI, we stop building the foundation that enables long-horizon judgment. A generation of knowledge workers who never did the grunt work will struggle to supervise AI doing that work—they won't know what "good" looks like or when the AI is subtly wrong.</p>

                        <p>This creates a second-order compression effect. As human long-horizon capability degrades, the threshold for "good enough" AI work drops. Organizations become less capable of detecting AI errors in complex work, which makes AI more acceptable for that work, which further erodes human capability to oversee it. The feedback loop accelerates displacement even in domains where human judgment nominally remains valuable.</p>

                        <h3>Re-employment probability</h3>

                        <p>Re-employment starts at a 60% baseline and blends five forces:</p>
                        <ul class='detail-list'>
                            <li><strong>Adaptability core (Q17, Q18, Q19):</strong> Transferability, learning speed, and performance move odds up or down (0.2 per weighted point, clamped to avoid runaway extremes).</li>
                            <li><strong>Task structure (Q5, Q6, Q8):</strong> Highly decomposable, standardized, and feedback-rich tasks are easier to automate and harder to pivot from, reducing re-employment odds by up to ~12 percentage points at the defaults. More tacit, varied work with slower feedback loops protects re-employment prospects.</li>
                            <li><strong>Labor tightness (Q15):</strong> A modest multiplier (+/-5% at defaults) reflecting how forgiving the market is.</li>
                            <li><strong>Global AI saturation penalty:</strong> As global AI capability matures (measured by when the blue technical feasibility curve hits 50%), the total number of available jobs shrinks. This penalty affects everyone equally based on the global state of AI: $\text{penalty}_{\text{global}} = p_{\max}\left(\dfrac{\max(0, p_{\text{blue,global}} - f_g)}{1 - f_g}\right)^{\alpha_g}$ with defaults $p_{\max}=0.35$, floor $f_g=0.20$, exponent $\alpha_g=1.3$.</li>
                            <li><strong>Relative timing bonus:</strong> Being displaced later than the global median provides an advantage—you've watched peers navigate transitions and can learn from their paths. The bonus scales linearly with delay: $\text{bonus}_{\text{relative}} = b_{\max} \cdot \min\left(1, \dfrac{t_{\text{yours}} - t_{\text{global}}}{s_r}\right)$ where $b_{\max}=0.15$ and the scale $s_r=5.0$ years at defaults. Full bonus applies when displaced 5+ years after the global median.</li>
                        </ul>
                        <p>Seniority applies a small boost, and results clamp between 10% and 85%.</p>

                        <div class='insight-callout'>
                            <h4>Protection mechanisms (user-actionable)</h4>
                            <ul>
                                <li>Move up hierarchy: reach Level 4–5 (own a domain/system) to reduce compression vulnerability.</li>
                                <li>Increase specialization: lower Q10 (make work harder to transfer to others).</li>
                                <li>Increase tacit/context: raise Q7 and Q9 (context-dependent, experiential work).</li>
                                <li>Reduce digitization overlap: lower Q4 where genuine (hybrid/physical workflows weaken AI amplification).</li>
                                <li>Build unique relationships: strengthen Q11/Q12 protective value.</li>
                                <li>Strengthen performance: raise Q19 to increase implementation delay and re-employment odds.</li>
                            </ul>
                        </div>
                    </section>

                    <section>
                        <h2>Hierarchy levels and seniority effects</h2>

                        <p>Your position in the organizational hierarchy significantly affects both your automation timeline and compression vulnerability. The model defines five hierarchy levels, each with distinct parameter adjustments:</p>

                        <div class='bubble-table'>
                            <div class='bubble-item'><span class='bubble-key'>Level 1: Many layers above</span><span class='bubble-val'>Entry-level; highest compression risk</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Level 2: Several layers above</span><span class='bubble-val'>Junior; moderate compression risk</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Level 3: Few above or peers</span><span class='bubble-val'>Mid-level; baseline parameters</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Level 4: Top of domain</span><span class='bubble-val'>Senior; reduced compression risk</span></div>
                            <div class='bubble-item'><span class='bubble-key'>Level 5: Unique/irreplaceable</span><span class='bubble-val'>Executive/owner; minimal compression risk</span></div>
                        </div>

                        <h3 class="h3-accent">Seniority profile adjustments</h3>

                        <p>Each hierarchy level applies four adjustments to the base model parameters:</p>

                        <ul class='detail-list'>
                            <li><strong>Theta lift ($\Delta\theta$):</strong> Adjusts the coverage threshold. Entry-level: -0.015 (automation triggers earlier); Level 5: +0.040 (requires higher AI capability before hazard activates). This reflects that senior roles typically require more comprehensive automation before replacement is viable.</li>
                            <li><strong>Hazard shield:</strong> Percentage reduction to base hazard rate. Ranges from 0% (Level 1) to 5% (Level 5). Senior roles have more organizational protection and replacement friction.</li>
                            <li><strong>Delay shift ($\Delta_{\text{seniority}}$):</strong> Adjusts implementation delay. Entry-level: -0.10 years (faster replacement); Level 5: +0.12 years (longer runway). Modified by job performance (Q19).</li>
                            <li><strong>Re-employment boost:</strong> Multiplier on re-employment probability. Ranges from 1.00&times; (Level 1) to 1.09&times; (Level 5). Senior experience improves job market prospects.</li>
                        </ul>

                        <h3 class="h3-accent">Task distribution shifts by seniority</h3>

                        <p>Hierarchy level also shifts your task duration profile. Entry-level roles skew toward shorter, more automatable tasks; senior roles skew toward longer, strategic tasks:</p>

                        <div class='parameter-table'>
                            <div class='table-label'>Seniority task weight shifts (added to base weights)</div>
                            <table>
                                <thead>
                                    <tr><th>Level</th><th>&lt;10m</th><th>10-45m</th><th>45m-3h</th><th>3-8h</th><th>&gt;12h</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td>1 (Entry)</td><td>+12%</td><td>+8%</td><td>-5%</td><td>-8%</td><td>-7%</td></tr>
                                    <tr><td>2 (Junior)</td><td>+5%</td><td>+3%</td><td>-2%</td><td>-3%</td><td>-3%</td></tr>
                                    <tr><td>3 (Mid)</td><td>0%</td><td>0%</td><td>0%</td><td>0%</td><td>0%</td></tr>
                                    <tr><td>4 (Senior)</td><td>-6%</td><td>-4%</td><td>+3%</td><td>+4%</td><td>+3%</td></tr>
                                    <tr><td>5 (Exec)</td><td>-12%</td><td>-9%</td><td>+6%</td><td>+8%</td><td>+7%</td></tr>
                                </tbody>
                            </table>
                            <p style="font-size: 0.9em; margin-top: 12px; color: #666;">These shifts are applied to base weights before normalization. Entry-level concentrates work in short tasks; executive level shifts to longer strategic tasks.</p>
                        </div>

                        <p>The combined effect is substantial: an entry-level role faces earlier automation (lower theta), faster implementation (negative delay shift), higher compression vulnerability (100% hierarchy exposure), and a task profile weighted toward short, easily-automated tasks. A Level 5 executive faces the opposite on all dimensions.</p>
                    </section>

                    <section>
                        <h2>Reading the outputs</h2>
                        <p>The chart shows two survival complements: blue for technical feasibility, green for realized displacement once friction and delay kick in. We integrate $\lambda(s)$ with Simpson's rule—the y-value at each point is the cumulative probability of job loss by that time. Use the controls to stress-test assumptions.</p>
                        <ul class='detail-list'>
                            <li><strong>Median timeline:</strong> A binary search finds the year where cumulative probability hits $50\%$. That becomes the headline median job-loss metric.</li>
                            <li><strong>Risk by 2030 or 2031:</strong> The model calculates years from the current date (when you access the page) to these target years, then evaluates $P_{\text{loss}}$ at that future horizon. For example, accessing the calculator in November 2025 means 2030 is ~4.1 years away. This ensures projections stay relevant as time passes.</li>
                            <li><strong>Personal timeline:</strong> The $25\%$, $50\%$, $75\%$, and $90\%$ milestones surface when they fall within the next $10$, $15$, $18$, and $25$ years respectively.</li>
                            <li><strong>Re-employment label:</strong> The probability is bucketed into Good, Moderate, Low, or Very Low for quick scanning, with the precise percentage alongside.</li>
                        </ul>
                    </section>

                    <section>
                        <h2>Worked Example: Mid-Level Data Analyst</h2>

                        <p>To make the abstract formulas concrete, let's walk through a complete calculation for a specific role: a mid-level data analyst at a mid-sized tech company. This example shows how questionnaire responses flow through the model to produce displacement timelines.</p>

                        <h3>Profile: Taylor, Data Analyst (Level 2)</h3>

                        <div class='insight-callout'>
                            <h4>Role characteristics</h4>
                            <p><strong>Background:</strong> Taylor is a data analyst at a 500-person SaaS company, reporting to a senior analytics manager. The role involves building dashboards, running A/B tests, creating performance reports, and doing ad-hoc analyses for product and marketing teams.</p>
                            <p><strong>Hierarchy:</strong> Level 2 (individual contributor with 3-5 years experience, senior analysts and managers above)</p>
                            <p><strong>Work structure:</strong> Mostly digital (SQL, Python, Tableau), somewhat standardized (many reports follow templates), moderate context requirements (needs to understand business logic and data quirks), fast feedback loops (stakeholders review outputs quickly)</p>
                            <p><strong>Organization:</strong> Tech company with moderate AI adoption appetite, competitive labor market, good digital infrastructure, average performance rating</p>
                        </div>

                        <h3>Step 1: Questionnaire responses</h3>

                        <p>Taylor's responses to key questions (1-5 Likert scale, where 1 = strongly disagree, 5 = strongly agree):</p>

                        <div class="parameter-table">
                            <table>
                                <tr><th>Question</th><th>Response</th><th>Interpretation</th></tr>
                                <tr><td>Q1: AI readiness in domain</td><td>4</td><td>Data analytics already seeing strong AI tools</td></tr>
                                <tr><td>Q2: Hierarchy level</td><td>Level 2</td><td>Mid-level IC, people above can absorb work</td></tr>
                                <tr><td>Q4: Work digitization</td><td>5</td><td>Nearly 100% digital workflows</td></tr>
                                <tr><td>Q5: Task decomposability</td><td>4</td><td>Most work breaks into clear chunks</td></tr>
                                <tr><td>Q6: Standardization</td><td>3</td><td>Mix of templated and custom analyses</td></tr>
                                <tr><td>Q7: Context dependency</td><td>3</td><td>Moderate - need business context but not deep tacit knowledge</td></tr>
                                <tr><td>Q8: Feedback speed</td><td>4</td><td>Fast iteration with stakeholders</td></tr>
                                <tr><td>Q10: Task reallocation feasibility</td><td>4</td><td>Senior analysts could absorb much of this work</td></tr>
                                <tr><td>Q13: Company AI adoption</td><td>3</td><td>Neither leading nor lagging</td></tr>
                                <tr><td>Q14: Labor cost pressure</td><td>3</td><td>Moderate pressure to optimize costs</td></tr>
                                <tr><td>Q17: Skill transferability</td><td>4</td><td>SQL, Python, data viz skills transfer well</td></tr>
                            </table>
                        </div>

                        <h3>Step 2: Calculate task distribution</h3>

                        <p>Based on questionnaire responses, the model maps Taylor's work onto five task duration buckets:</p>

                        <div class="parameter-table">
                            <table>
                                <tr><th>Bucket</th><th>Duration</th><th>Weight</th><th>Reasoning</th></tr>
                                <tr><td>1</td><td>5 min</td><td>15%</td><td>Quick data pulls, simple updates</td></tr>
                                <tr><td>2</td><td>30 min</td><td>35%</td><td>Standard reports, dashboard updates</td></tr>
                                <tr><td>3</td><td>2 hours</td><td>30%</td><td>Ad-hoc analyses, A/B test reports</td></tr>
                                <tr><td>4</td><td>6 hours</td><td>15%</td><td>Complex multi-dataset analyses</td></tr>
                                <tr><td>5</td><td>12+ hours</td><td>5%</td><td>Major projects requiring stakeholder iteration</td></tr>
                            </table>
                        </div>

                        <p>The distribution skews toward shorter tasks (50% in buckets 1-2) because the role involves significant routine reporting, but retains some longer-horizon work (20% in buckets 4-5) for complex projects.</p>

                        <h3>Step 3: Domain friction and capability timeline</h3>

                        <p><strong>Domain selection:</strong> Data analytics maps to "Software Engineering / Data Science" domain</p>
                        <p><strong>Base friction multiplier:</strong> 1.05× (low friction - digital, measurable outputs, similar to AI training data)</p>
                        <p><strong>Adjusted friction from questionnaire:</strong> Moderate context dependency (Q7=3) and some tacit knowledge offset by high digitization, final domain penalty ≈ 1.15×</p>

                        <p><strong>Current AI capability (November 2025):</strong> GPT-5.1-Codex-Max baseline at ~162 minutes (50th percentile), ~31 minutes (80th percentile)</p>
                        <p><strong>Reliability penalty at 95%:</strong> Factor of ~33.4×, effective horizon contracts to ~4.8 minutes</p>
                        <p><strong>After domain friction (1.15×):</strong> 4.8 / 1.15 ≈ 4.2 minutes effective starting capability</p>

                        <p><strong>Capability doubling time:</strong> 7 months (from METR trend)</p>

                        <h3>Step 4: Task gates and job readiness</h3>

                        <p>AI job readiness $A_{\text{job}}(t)$ is the weighted sum of cleared task gates. Starting from 4.2 minutes effective capability:</p>

                        <div class="parameter-table">
                            <table>
                                <tr><th>Time</th><th>Capability</th><th>Cleared Gates</th><th>Job Readiness</th></tr>
                                <tr><td>Now (Nov 2025)</td><td>4.2 min</td><td>None (below 5 min)</td><td>0%</td></tr>
                                <tr><td>+7 months</td><td>8.4 min</td><td>Bucket 1 (5 min)</td><td>15%</td></tr>
                                <tr><td>+14 months</td><td>16.8 min</td><td>Buckets 1-2</td><td>50%</td></tr>
                                <tr><td>+21 months</td><td>33.6 min</td><td>Buckets 1-2</td><td>50%</td></tr>
                                <tr><td>+28 months</td><td>67 min</td><td>Buckets 1-3</td><td>80%</td></tr>
                                <tr><td>+35 months</td><td>134 min</td><td>Buckets 1-3</td><td>80%</td></tr>
                                <tr><td>+42 months</td><td>268 min</td><td>Buckets 1-4</td><td>95%</td></tr>
                            </table>
                        </div>

                        <p>The job readiness threshold (50%) is crossed around 14 months from now (early 2027). This is when the automation hazard channel begins activating.</p>

                        <h3>Step 5: Compression hazard</h3>

                        <p><strong>Hierarchy vulnerability:</strong> Level 2 → $V_{\text{hierarchy}} = (6-2)/5 = 0.80$ (80% vulnerable)</p>

                        <p><strong>Senior productivity amplification:</strong></p>
                        <ul class="detail-list">
                            <li>Base digitization: Q4=5 → 100% digital</li>
                            <li>Discount factors: Context (Q7=3, 35% weight), Tacit knowledge moderate, Decomposability high (Q5=4, 20% weight), Standardization moderate (Q6=3, 15% weight)</li>
                            <li>Net learnability: ~70% (AI can learn from digital outputs despite some context requirements)</li>
                            <li>Amplification factor: 70% × AI readiness × 2.0 max boost</li>
                            <li>At 50% job readiness: $B_{\text{amp}} = 0.70 \times 0.50 \times 2.0 = 0.70$ (seniors get 70% productivity boost, or 1.7× output)</li>
                        </ul>

                        <p><strong>Task reallocation feasibility:</strong> Q10=4 → high feasibility (0.70 on 0-1 scale)</p>

                        <p><strong>Compression readiness:</strong> $C_{\text{ready}} = 0.7 \times 0.7 + 0.3 \times (0.70 \times 0.50) = 0.49 + 0.105 = 0.595$ at 50% job readiness</p>

                        <p><strong>Compression hazard:</strong> $\lambda_{\text{comp}} = 0.45 \times 0.80 \times 0.595 = 0.214$ per year once compression gate opens (~33% job readiness, reached at ~10 months)</p>

                        <p>Compression hazard activates <em>earlier</em> than automation hazard (10 months vs. 14 months) because it only requires 33% job readiness. For Taylor, compression is the dominant near-term risk.</p>

                        <h3>Step 6: Implementation delay</h3>

                        <p><strong>Initial delay calculation:</strong> Based on organizational context (Q13-Q16) and individual leverage (Q19):</p>
                        <ul class="detail-list">
                            <li>Company adoption (Q13=3): Moderate → 0.0 contribution to delay</li>
                            <li>Labor cost pressure (Q14=3): Moderate → 0.0 contribution</li>
                            <li>Performance (Q19=3): Average → 0.0 multiplier adjustment</li>
                            <li><strong>Initial delay $\Delta_0$:</strong> ~1.5 years (mid-range between aggressive and defensive)</li>
                        </ul>

                        <p><strong>Delay decay:</strong> $\lambda_{\text{decay}} \approx 0.03$/year (moderate decay rate)</p>
                        <p><strong>Dynamic delay:</strong> $\Delta(t) = 1.5 \times e^{-0.03t}$</p>

                        <ul class="detail-list">
                            <li>At t=1 year: Delay = 1.46 years</li>
                            <li>At t=2 years: Delay = 1.41 years</li>
                            <li>At t=3 years: Delay = 1.37 years</li>
                        </ul>

                        <p>The green curve shifts the blue curve rightward by this time-decaying delay.</p>

                        <h3>Step 7: Combined hazard and survival curves</h3>

                        <p><strong>Blue curve (technical automation only):</strong></p>
                        <ul class="detail-list">
                            <li>Hazard activates when $A_{\text{job}} \geq 50\%$ (~14 months, early 2027)</li>
                            <li>Hazard ramps from 0 to max (0.45/year) with slope $\gamma = 8.0$</li>
                            <li>By t=2 years: Cumulative probability ≈ 15%</li>
                            <li>By t=3 years: Cumulative probability ≈ 45%</li>
                            <li>By t=4 years: Cumulative probability ≈ 70%</li>
                        </ul>

                        <p><strong>Green curve (implementation + compression):</strong></p>
                        <ul class="detail-list">
                            <li>Compression hazard starts at ~10 months (33% job readiness)</li>
                            <li>Combined hazard = compression + delayed automation (capped at 0.60/year)</li>
                            <li>By t=2 years: Cumulative probability ≈ 25% (compression driving early risk)</li>
                            <li>By t=3 years: Cumulative probability ≈ 52% (both channels active)</li>
                            <li>By t=4 years: Cumulative probability ≈ 75%</li>
                        </ul>

                        <p><strong>Key insight:</strong> Taylor's green curve arrives earlier than blue because Level 2 hierarchy + high task reallocation feasibility makes compression the dominant near-term threat. The 1.5-year implementation delay prevents immediate displacement but doesn't fully offset compression risk.</p>

                        <h3>Step 8: Re-employment probability</h3>

                        <p>Starting from 60% baseline:</p>
                        <ul class="detail-list">
                            <li><strong>Skill transferability (Q17=4):</strong> +8% (SQL, Python, visualization skills transfer)</li>
                            <li><strong>Task structure penalty:</strong> High decomposability (Q5=4) and fast feedback (Q8=4) make skills more automatable → -6%</li>
                            <li><strong>Seniority boost:</strong> Level 2 → +2%</li>
                            <li><strong>Final re-employment:</strong> 60% + 8% - 6% + 2% = <strong>64%</strong> (Moderate)</li>
                        </ul>

                        <h3>Final output</h3>

                        <div class='insight-callout'>
                            <h4>Taylor's displacement forecast</h4>
                            <p><strong>Median timeline (green curve):</strong> ~3 years (50% probability by early 2029)</p>
                            <p><strong>Risk breakdown:</strong></p>
                            <ul>
                                <li>By 2 years: 25% probability (primarily compression)</li>
                                <li>By 3 years: 52% probability (compression + delayed automation)</li>
                                <li>By 4 years: 75% probability (both channels fully active)</li>
                            </ul>
                            <p><strong>Re-employment probability:</strong> 64% (Moderate) - transferable technical skills help but role automation reduces demand</p>
                            <p><strong>Primary threat:</strong> Workforce compression (earlier onset than full automation due to Level 2 hierarchy vulnerability)</p>
                            <p><strong>Recommendations:</strong> Taylor should focus on building senior-level skills (strategic thinking, cross-functional communication, complex problem identification) to move up hierarchy, or pivot toward less automatable adjacent roles (product analytics requiring deep business context, data platform engineering) within 2-3 years.</p>
                        </div>

                        <h3>How to use this example</h3>

                        <p>This walkthrough demonstrates:</p>
                        <ul class="detail-list">
                            <li><strong>How questionnaire responses map to parameters:</strong> Each Likert scale answer feeds specific calculations (hierarchy vulnerability, amplification factors, delay parameters)</li>
                            <li><strong>The role of task distribution:</strong> Taylor's concentration in short-to-medium tasks (50% in buckets 1-2) makes job readiness cross thresholds quickly</li>
                            <li><strong>Why compression can dominate:</strong> Level 2 hierarchy (80% vulnerable) + high reallocation feasibility (Q10=4) means compression activates before automation and drives near-term risk</li>
                            <li><strong>Implementation delay effects:</strong> 1.5-year delay shifts automation hazard but doesn't prevent compression, which is why green curve still arrives earlier than you might expect</li>
                            <li><strong>What the numbers mean:</strong> A "3-year median" doesn't mean "you'll be displaced in exactly 3 years"—it means 52% probability by that point, with substantial uncertainty on either side</li>
                        </ul>

                        <p>Your own calculation will differ based on your specific questionnaire responses, but the mechanical flow is identical. The model is deterministic: same inputs always produce same outputs. The uncertainty comes from not knowing whether your inputs correctly represent reality.</p>
                    </section>

                    <section>
                        <h2>How to work with the model</h2>
                        <ol class='action-list'>
                            <li>Start with the preset that feels closest to your role, then tweak one cluster of questions at a time so you can see which dimensions move the hazard.</li>
                            <li>Stress-test the extremes: set AI readiness to five while leaving friction high, then flip it. The gap between those runs shows which factors matter most for you.</li>
                            <li>Pair the re-employment score with the green curve. Fast hazard plus weak re-employment means you should start upskilling or job searching now; slow hazard plus strong re-employment means you have time to be strategic.</li>
                        </ol>
                        <p>Use the weight structure as a checklist: strengthen the protective factors you can influence, note which assumptions you can't change, and revisit the calculator as real-world signals shift.</p>
                    </section>

                    <section>
                        <h2>Guide to Model Tuning</h2>
                        <p>The tuning panel exposes every parameter used in the hazard and compression calculations. Presets are grouped by the math they touch so you can mix capability, friction, compression, and rollout assumptions independently:</p>
                        <ul class='detail-list'>
                            <li><strong>Model Capability:</strong> Conservative / Baseline / Fast-Takeoff adjust only capability growth (METR doubling time and gate softness).</li>
                            <li><strong>Task Friction:</strong> Less / Baseline / More rescale domain and industry penalties that damp effective capability before it reaches the gates.</li>
                            <li><strong>Workforce Compression:</strong> Less / Baseline / More move the green-curve mechanics (reallocation weights, amplification, gate threshold, readiness floor).</li>
                            <li><strong>Adoption Guardrails:</strong> More drag / Baseline / Less drag tighten or loosen hazard caps/thresholds and implementation delay decay to explore deployment speed.</li>
                        </ul>
                        <p>These presets only set parameter values; you can override any field afterward. They do not change the underlying equations, only the assumed coefficients for capability, friction, compression, and rollout speed.</p>
                    </section>

                </div>
            </article>
        </div>
    </main>

    <script>
        // Build and highlight a subtle progress nav (desktop only)
        document.addEventListener('DOMContentLoaded', () => {
            // Wrap sections with header/body so structure is explicit for the nav
            const applySectionStructure = () => {
                const sections = document.querySelectorAll('.article-body > section');
                sections.forEach(sec => {
                    if (sec.querySelector('.section-body')) return;
                    const heading = sec.querySelector('h2, h3, h4');
                    if (!heading) return;
                    const headerEl = document.createElement('header');
                    headerEl.className = 'section-header';
                    sec.insertBefore(headerEl, heading);
                    headerEl.appendChild(heading);
                    const bodyEl = document.createElement('div');
                    bodyEl.className = 'section-body';
                    while (headerEl.nextSibling) {
                        bodyEl.appendChild(headerEl.nextSibling);
                    }
                    sec.appendChild(bodyEl);
                });
            };

            applySectionStructure();

            const list = document.getElementById('progress-list');
            const nav = document.querySelector('.progress-nav');
            if (!list) return;

            const headings = Array.from(document.querySelectorAll('main h2, main h3, article h2, article h3, .article-body h2, .article-body h3'))
                .filter(h => h.textContent.trim().length > 0);
            if (!headings.length) return;

            headings.forEach((h, idx) => {
                if (!h.id) {
                    h.id = `section-${idx + 1}`;
                }
                const li = document.createElement('li');
                const depth = h.tagName.toLowerCase() === 'h3' ? 'depth-3' : 'depth-2';
                li.classList.add(depth);
                const a = document.createElement('a');
                a.href = `#${h.id}`;
                a.textContent = h.textContent.trim();
                a.className = depth;
                li.appendChild(a);
                list.appendChild(li);
            });

            const links = Array.from(list.querySelectorAll('a'));
            const updateFill = (activeIdx) => {
                if (!nav || links.length <= 1) return;
                const pct = activeIdx <= 0 ? 0 : Math.round((activeIdx / (links.length - 1)) * 100);
                nav.style.setProperty('--progress-fill', `${pct}%`);
            };

            const setActive = (id) => {
                let activeIdx = 0;
                links.forEach((link, idx) => {
                    const isActive = link.getAttribute('href') === `#${id}`;
                    link.classList.toggle('active', isActive);
                    link.parentElement && link.parentElement.classList.toggle('active', isActive);
                    if (isActive) activeIdx = idx;
                });
                updateFill(activeIdx);
                const activeLi = links[activeIdx]?.parentElement;
                if (activeLi && nav) {
                    activeLi.scrollIntoView({ block: 'nearest', behavior: 'smooth' });
                }
            };

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        setActive(entry.target.id);
                    }
                });
            }, {
                rootMargin: '-40% 0px -40% 0px',
                threshold: [0.1, 0.5, 1.0]
            });

            headings.forEach(h => observer.observe(h));
            setActive(headings[0].id);
        });
    </script>

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js' async></script>
    <script src='navigation.js'></script>
</body>

</html>
